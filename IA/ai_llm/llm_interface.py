# arquivo: IA/ai_llm/interface_llm.py
"""
Interface LLM - Comunica√ß√£o com Modelo de Linguagem
Otimizado para respostas r√°pidas e fallback inteligente
VERS√ÉO CORRIGIDA: Traduzida para portugu√™s e com corre√ß√µes de bugs
"""

import os
import ollama
import json
import logging
import re
from typing import Union, Dict, List
import time

from core.gerenciador_sessao import obter_contexto_conversa
from utils.extrator_quantidade import detectar_modificadores_quantidade
from utils.analisador_resposta import extrair_json_da_resposta_ia
from utils.classificador_intencao import detectar_intencao_usuario_com_ia, detectar_intencao_com_sistemas_criticos

# --- Configura√ß√µes Globais (MOVIDAS PARA ANTES DAS FUN√á√ïES) ---
NOME_MODELO_OLLAMA = os.getenv("OLLAMA_MODEL_NAME", "llama3.1")
HOST_OLLAMA = os.getenv("OLLAMA_HOST", "http://host.docker.internal:11434")
USAR_FALLBACK_IA = os.getenv("USE_AI_FALLBACK", "true").lower() == "true"
TIMEOUT_IA = int(os.getenv("AI_TIMEOUT", "5"))  # Timeout em segundos
AMBIENTE = os.getenv("ENVIRONMENT", "production")

FERRAMENTAS_DISPONIVEIS = [
    "encontrar_cliente_por_cnpj",
    "obter_produtos_mais_vendidos", 
    "obter_produtos_mais_vendidos_por_nome",
    "adicionar_item_ao_carrinho",
    "atualizar_item_carrinho",
    "visualizar_carrinho",
    "finalizar_pedido",
    "lidar_com_conversa_casual",
    "iniciar_novo_pedido",
    "mostrar_mais_produtos",
    "reportar_produto_incorreto",
    "perguntar_continuar_ou_finalizar",
    "limpar_carrinho",
    "atualizar_carrinho_inteligente",
    "busca_inteligente_com_promocoes"
]

# Cache do prompt para evitar leitura repetida do arquivo
_cache_prompt = None
_tempo_cache_prompt = 0

def validar_configuracao():
    """Valida configura√ß√£o cr√≠tica no startup"""
    variaveis_obrigatorias = {
        "OLLAMA_HOST": "Host do Ollama",
        "OLLAMA_MODEL_NAME": "Nome do modelo Ollama"
    }
    
    variaveis_ausentes = []
    for nome_var, descricao in variaveis_obrigatorias.items():
        if not os.getenv(nome_var):
            variaveis_ausentes.append(f"{nome_var} ({descricao})")
    
    if variaveis_ausentes:
        raise ValueError(f"Vari√°veis de ambiente obrigat√≥rias ausentes:\n" + 
                        "\n".join(f"- {var}" for var in variaveis_ausentes))

def obter_cnpjs_teste() -> List[str]:
    """Obt√©m CNPJs de teste apenas em ambiente de desenvolvimento"""
    if AMBIENTE == "development":
        return [
            "11222333000181",  # CNPJ de teste v√°lido
            "12345678910203",  # CNPJ usado nos testes
            "12365562103231",  # CNPJ usado nos logs
            "11111111111111",  # Para testes simples 
            "12345678000195"   # Outro CNPJ de teste
        ]
    return []  # Produ√ß√£o: sem CNPJs de teste

def verificar_conexao_ollama() -> bool:
    """Verifica se o Ollama est√° dispon√≠vel e funcionando"""
    logging.debug("Verificando a conex√£o com o Ollama.")
    try:
        cliente = ollama.Client(host=HOST_OLLAMA)
        # Tenta fazer uma chamada simples para verificar conectividade
        resposta = cliente.chat(
            model=NOME_MODELO_OLLAMA,
            messages=[{"role": "user", "content": "test"}],
            options={"num_predict": 1}
        )
        logging.debug("Conex√£o com o Ollama bem-sucedida.")
        return True
    except Exception as e:
        logging.warning(f"Ollama n√£o dispon√≠vel: {e}")
        return False


def is_valid_cnpj(cnpj: str) -> bool:
    """
    üÜï NOVA FUN√á√ÉO: Valida se uma string √© um CNPJ v√°lido.
    Aceita CNPJ com ou sem pontua√ß√£o (XX.XXX.XXX/XXXX-XX ou XXXXXXXXXXXXXX)
    """
    logging.debug(f"Validando CNPJ: '{cnpj}'")
    print(f">>> CONSOLE: üîç [IS_VALID_CNPJ] Validando CNPJ: '{cnpj}'")
    
    # Remove caracteres n√£o num√©ricos (pontos, barras, tra√ßos)
    cnpj_digits = re.sub(r'\D', '', cnpj)
    print(f">>> CONSOLE: üîç [IS_VALID_CNPJ] CNPJ apenas d√≠gitos: '{cnpj_digits}'")
    
    # Verifica se tem 14 d√≠gitos
    if len(cnpj_digits) != 14:
        print(f">>> CONSOLE: ‚ùå [IS_VALID_CNPJ] CNPJ n√£o tem 14 d√≠gitos (tem {len(cnpj_digits)})")
        return False
    
    # üÜï ACEITA CNPJs DE TESTE PARA DESENVOLVIMENTO
    test_cnpjs = [
        "11222333000181",  # CNPJ de teste v√°lido
        "12345678910203",  # CNPJ usado nos testes
        "12365562103231",  # CNPJ usado nos logs
        "11111111111111",  # Para testes simples 
        "12345678000195",  # Outro CNPJ de teste
    ]
    
    print(f">>> CONSOLE: üîç [IS_VALID_CNPJ] Verificando se '{cnpj_digits}' est√° na lista de CNPJs de teste...")
    
    if cnpj_digits in test_cnpjs:
        print(f">>> CONSOLE: ‚úÖ [IS_VALID_CNPJ] CNPJ de teste v√°lido encontrado: {cnpj_digits}")
        return True
    
    # Verifica se n√£o s√£o todos iguais (ex: 11111111111111) - EXCETO se for de teste
    if cnpj_digits == cnpj_digits[0] * 14 and cnpj_digits not in test_cnpjs:
        print(f">>> CONSOLE: ‚ùå [IS_VALID_CNPJ] CNPJ com todos d√≠gitos iguais: {cnpj_digits}")
        return False
    
    print(f">>> CONSOLE: üîç [IS_VALID_CNPJ] Iniciando valida√ß√£o matem√°tica dos d√≠gitos verificadores...")
    
    # Valida√ß√£o dos d√≠gitos verificadores
    try:
        # Verifica primeiro d√≠gito verificador
        sequence = [int(cnpj_digits[i]) for i in range(12)]
        weights1 = [5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
        sum1 = sum(sequence[i] * weights1[i] for i in range(12))
        digit1 = ((sum1 % 11) < 2) and 0 or (11 - (sum1 % 11))
        
        if digit1 != int(cnpj_digits[12]):
            return False
        
        # Verifica segundo d√≠gito verificador
        sequence.append(digit1)
        weights2 = [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
        sum2 = sum(sequence[i] * weights2[i] for i in range(13))
        digit2 = ((sum2 % 11) < 2) and 0 or (11 - (sum2 % 11))
        
        result = digit2 == int(cnpj_digits[13])
        print(f">>> CONSOLE: {'‚úÖ' if result else '‚ùå'} [IS_VALID_CNPJ] Valida√ß√£o matem√°tica: {result}")
        return result
        
    except (ValueError, IndexError) as e:
        print(f">>> CONSOLE: ‚ùå [IS_VALID_CNPJ] Erro na valida√ß√£o matem√°tica: {e}")
        return False


def detectar_intencao_limpar_carrinho(mensagem: str) -> bool:
    """
    Detecta inten√ß√£o de limpar/esvaziar carrinho.
    """
    logging.debug(f"Detectando inten√ß√£o de limpar carrinho na mensagem: '{mensagem}'")
    mensagem_minuscula = mensagem.lower().strip()
    
    # Comandos expl√≠citos de limpeza de carrinho
    comandos_limpeza = [
        # Comandos diretos
        'esvaziar carrinho', 'limpar carrinho', 'zerar carrinho',
        'resetar carrinho', 'apagar carrinho', 'deletar carrinho',
        
        # Varia√ß√µes com "tudo"
        'esvaziar tudo', 'limpar tudo', 'zerar tudo', 
        'apagar tudo', 'deletar tudo', 'remover tudo',
        
        # Comandos de rein√≠cio
        'come√ßar de novo', 'recome√ßar', 'reiniciar',
        'do zero', 'novo pedido', 'nova compra',
        
        # Comandos informais
        'limpa', 'esvazia', 'zera', 'apaga'
    ]
    
    # Verifica comandos exatos
    for comando in comandos_limpeza:
        if comando in mensagem_minuscula:
            logging.debug(f"Inten√ß√£o de limpar carrinho detectada pelo comando: '{comando}'")
            return True
    
    # Padr√µes mais flex√≠veis
    padroes_limpeza = [
        r'\b(limpar|esvaziar|zerar|apagar|deletar|remover)\s+(o\s+)?carrinho\b',
        r'\b(carrinho|tudo)\s+(limpo|vazio|zerado)\b',
        r'\bcomeca\w*\s+de\s+novo\b',
        r'\bdo\s+zero\b',
        r'\breinicia\w*\s+(carrinho|tudo|compra)\b'
    ]
    
    for padrao in padroes_limpeza:
        if re.search(padrao, mensagem_minuscula):
            logging.debug(f"Inten√ß√£o de limpar carrinho detectada pelo padr√£o: '{padrao}'")
            return True
    
    logging.debug("Nenhuma inten√ß√£o de limpar carrinho detectada.")
    return False


def detectar_contexto_checkout(dados_sessao: Dict) -> Dict:
    """
    üÜï NOVA FUN√á√ÉO: Detecta se estamos em contexto de finaliza√ß√£o/checkout.
    """
    logging.debug("Detectando contexto de checkout.")
    context = {
        'awaiting_cnpj': False,
        'last_request_was_cnpj': False,
        'checkout_initiated': False
    }
    
    # Verifica hist√≥rico recente
    history = dados_sessao.get('conversation_history', [])
    
    if not history:
        return context
    
    # Analisa √∫ltimas 3 mensagens do bot
    recent_bot_messages = []
    for msg in reversed(history):
        if msg.get('role') == 'assistant':
            recent_bot_messages.append(msg.get('message', '').lower())
            if len(recent_bot_messages) >= 3:
                break
    
    # Verifica se a √∫ltima mensagem do bot pediu CNPJ
    if recent_bot_messages:
        last_bot_msg = recent_bot_messages[0]
        
        cnpj_request_patterns = [
            'cnpj', 'finalizar', 'checkout', 'compra',
            'identificar', 'cadastro', 'cliente'
        ]
        
        if any(pattern in last_bot_msg for pattern in cnpj_request_patterns):
            context['awaiting_cnpj'] = True
            context['last_request_was_cnpj'] = True
    
    # Verifica se checkout foi iniciado recentemente
    for msg in recent_bot_messages:
        if any(word in msg for word in ['finalizar', 'checkout', 'cnpj']):
            context['checkout_initiated'] = True
            break
    
    logging.debug(f"Contexto de checkout detectado: {context}")
    return context


def load_prompt_template() -> str:
    """Carrega o prompt do arquivo de texto 'gav_prompt.txt' com cache."""
    logging.debug("Carregando template do prompt.")
    global _prompt_cache, _prompt_cache_time

    # Usa cache se foi carregado h√° menos de 5 minutos
    if _prompt_cache and (time.time() - _prompt_cache_time) < 300:
        logging.debug("Usando prompt em cache.")
        return _prompt_cache

    prompt_path = os.path.join("ai_llm", "gav_prompt.txt")

    try:
        logging.info(f"[llm_interface.py] Carregando prompt de: {prompt_path}")
        with open(prompt_path, "r", encoding="utf-8") as f:
            content = f.read()
            _prompt_cache = content
            _prompt_cache_time = time.time()
            logging.info(
                f"[llm_interface.py] Prompt carregado e cacheado. Tamanho: {len(content)} caracteres"
            )
            return content
    except FileNotFoundError:
        logging.warning(
            f"[llm_interface.py] Arquivo '{prompt_path}' n√£o encontrado. Usando prompt de fallback."
        )
        return get_fallback_prompt()


def get_fallback_prompt() -> str:
    """Prompt de emerg√™ncia caso o arquivo n√£o seja encontrado."""
    logging.debug("Obtendo prompt de fallback.")
    return """Voc√™ √© G.A.V., o Gentil Assistente de Vendas do Comercial Esperan√ßa. Seu tom √© PROFISSIONAL, DIRETO e OBJETIVO. 

ESTILO: Respostas curtas com pr√≥xima a√ß√£o expl√≠cita. Liste at√© 3 op√ß√µes por vez; pe√ßa escolha por n√∫mero ("1, 2 ou 3").

FERRAMENTAS: get_top_selling_products, get_top_selling_products_by_name, adicionar_item_ao_carrinho, visualizar_carrinho, atualizar_item_carrinho, checkout, lidar_conversa, perguntar_continuar_ou_finalizar, limpar_carrinho

COMANDOS ESPECIAIS:
- "esvaziar carrinho", "limpar carrinho" ‚Üí use limpar_carrinho
- CNPJ (14 d√≠gitos) quando solicitado ‚Üí use find_customer_by_cnpj

SEMPRE RESPONDA EM JSON V√ÅLIDO COM tool_name E parameters!"""


def extract_numeric_selection(message: str) -> Union[int, None]:
    """Extrai sele√ß√£o num√©rica (1 a 50) da mensagem do usu√°rio."""
    logging.debug(f"Extraindo sele√ß√£o num√©rica da mensagem: '{message}'")
    # Busca n√∫meros de 1 a 50 isolados na mensagem
    numbers = re.findall(r"\b([1-9]|[1-4][0-9]|50)\b", message.strip())
    if numbers:
        try:
            num = int(numbers[0])
            if 1 <= num <= 50:  # Valida√ß√£o adicional para at√© 50 produtos
                logging.debug(f"Sele√ß√£o num√©rica extra√≠da: {num}")
                return num
        except ValueError:
            pass
    logging.debug("Nenhuma sele√ß√£o num√©rica encontrada.")
    return None


def detect_quantity_keywords(message: str) -> Union[float, None]:
    """Detecta palavras-chave de quantidade na mensagem."""
    logging.debug(f"Detectando palavras-chave de quantidade na mensagem: '{message}'")
    message_lower = message.lower().strip()

    # Mapeamento de palavras para quantidades
    quantity_map = {
        "um": 1,
        "uma": 1,
        "dois": 2,
        "duas": 2,
        "tr√™s": 3,
        "tres": 3,
        "quatro": 4,
        "cinco": 5,
        "seis": 6,
        "sete": 7,
        "oito": 8,
        "nove": 9,
        "dez": 10,
        "meia d√∫zia": 6,
        "meia duzia": 6,
        "uma d√∫zia": 12,
        "uma duzia": 12,
        "d√∫zia": 12,
        "duzia": 12,
    }

    for word, quantity in quantity_map.items():
        if word in message_lower:
            logging.debug(f"Palavra-chave de quantidade detectada: '{word}' -> {quantity}")
            return float(quantity)

    # Busca n√∫meros decimais
    decimal_match = re.search(r"\b(\d+(?:[.,]\d+)?)\b", message)
    if decimal_match:
        number_str = decimal_match.group(1).replace(",", ".")
        try:
            quantity = float(number_str)
            logging.debug(f"Quantidade num√©rica detectada: {quantity}")
            return quantity
        except ValueError:
            pass

    logging.debug("Nenhuma palavra-chave de quantidade encontrada.")
    return None


def melhorar_consciencia_contexto(mensagem_usuario: str, dados_sessao: Dict) -> Dict:
    """
    üÜï VERS√ÉO MELHORADA: Melhora a consci√™ncia contextual analisando estado da sess√£o.
    """
    logging.debug(f"Aprimorando a consci√™ncia de contexto para a mensagem: '{mensagem_usuario}'")
    context = {
        "has_cart_items": len(dados_sessao.get("shopping_cart", [])) > 0,
        "cart_count": len(dados_sessao.get("shopping_cart", [])),
        "has_pending_products": len(dados_sessao.get("last_shown_products", [])) > 0,
        "last_action": dados_sessao.get("last_bot_action", ""),
        "customer_identified": bool(dados_sessao.get("customer_context")),
        "recent_search": dados_sessao.get("last_kb_search_term"),
        "numeric_selection": extract_numeric_selection(mensagem_usuario),
        "inferred_quantity": detect_quantity_keywords(mensagem_usuario),
        "conversation_history": dados_sessao.get("conversation_history", [])
    }

    # üÜï DETECTA COMANDOS DE LIMPEZA DE CARRINHO
    context["limpar_carrinho_command"] = detect_cart_clearing_intent(mensagem_usuario)
    
    # üÜï DETECTA CONTEXTO DE CHECKOUT/FINALIZA√á√ÉO
    checkout_context = detect_checkout_context(dados_sessao)
    context.update(checkout_context)
    
    # üÜï DETECTA SE √â UM CNPJ V√ÅLIDO
    context["is_valid_cnpj"] = is_valid_cnpj(mensagem_usuario)
    context["is_cnpj_in_checkout_context"] = (
        context["is_valid_cnpj"] and 
        (context["awaiting_cnpj"] or context["checkout_initiated"])
    )

    # Detecta padr√µes espec√≠ficos
    message_lower = mensagem_usuario.lower().strip()

    # Comandos diretos de carrinho
    if any(cmd in message_lower for cmd in ["carrinho", "ver carrinho"]):
        context["direct_cart_command"] = True

    # Comandos de finaliza√ß√£o
    if any(cmd in message_lower for cmd in ["finalizar", "fechar", "checkout"]):
        context["direct_checkout_command"] = True

    # Comandos de continuar compra
    if any(cmd in message_lower for cmd in ["continuar", "mais produtos", "outros"]):
        context["continue_shopping"] = True
        
    context["conversation_context"] = analyze_conversation_context(
        context["conversation_history"], mensagem_usuario
    )

    # Detecta g√≠rias de produtos
    product_slang = {
        "refri": "refrigerante",
        "zero": "coca zero",
        "lata": "lata",
        "2l": "2 litros",
        "pet": "garrafa pet",
    }

    for slang, meaning in product_slang.items():
        if slang in message_lower:
            context["detected_slang"] = {slang: meaning}
            break

    # Determina est√°gio da compra
    purchase_stage = dados_sessao.get("purchase_stage", "greeting")

    greeting_keywords = [
        "oi",
        "ol√°",
        "ola",
        "bom dia",
        "boa tarde",
        "boa noite",
        "e a√≠",
        "e ai",
    ]
    search_keywords = [
        "buscar",
        "procurar",
        "produto",
        "comprar",
        "preciso",
        "quero",
        "produtos",
        "mais vendidos",
    ]

    # üÜï DETECTA CONTEXTO DE CHECKOUT BASEADO NA √öLTIMA A√á√ÉO DO BOT
    last_action = context.get("last_action", "")
    if (
        context.get("direct_checkout_command") or 
        context.get("awaiting_cnpj") or
        last_action == "AWAITING_CHECKOUT_CONFIRMATION"
    ):
        purchase_stage = "checkout"
    elif context.get("direct_cart_command"):
        purchase_stage = "cart"
    elif any(word in message_lower for word in greeting_keywords):
        purchase_stage = "greeting"
    elif (
        any(word in message_lower for word in search_keywords)
        or context.get("has_pending_products")
        or context.get("recent_search")
    ):
        purchase_stage = "search"
    elif context.get("has_cart_items"):
        purchase_stage = "cart"

    context["purchase_stage"] = purchase_stage
    dados_sessao["purchase_stage"] = purchase_stage

    logging.debug(f"Consci√™ncia de contexto aprimorada: {context}")
    return context


def analyze_conversation_context(history: List[Dict], current_message: str) -> Dict:
    """Analisa o contexto da conversa para melhor interpreta√ß√£o."""
    logging.debug(f"Analisando o contexto da conversa para a mensagem: '{current_message}'")
    context_analysis = {
        "last_bot_action_type": None,
        "waiting_for_selection": False,
        "continue_or_checkout_flow": False,
        "recent_products_shown": False
    }
    
    if not history:
        return context_analysis
    
    # Analisa √∫ltimas mensagens do bot
    recent_bot_messages = []
    for msg in reversed(history[-10:]):  # √öltimas 10 mensagens
        if msg.get("role") == "assistant":
            recent_bot_messages.append(msg.get("message", "").lower())
            if len(recent_bot_messages) >= 3:  # Analisa at√© 3 mensagens do bot
                break
    
    if recent_bot_messages:
        last_bot_msg = recent_bot_messages[0]
        
        # Bot mostrou produtos e est√° esperando sele√ß√£o
        if any(phrase in last_bot_msg for phrase in [
            "responda 1, 2 ou 3", "escolha", "qual voc√™ quer",
            "digite o n√∫mero", "selecione"
        ]):
            context_analysis["waiting_for_selection"] = True
            context_analysis["recent_products_shown"] = True
        
        # Bot perguntou se quer continuar ou finalizar
        if "continuar" in last_bot_msg and "finalizar" in last_bot_msg:
            context_analysis["continue_or_checkout_flow"] = True
        
        # Bot adicionou item ao carrinho recentemente
        if any(phrase in last_bot_msg for phrase in [
            "adicionado", "adicionei", "no carrinho"
        ]):
            context_analysis["last_bot_action_type"] = "added_to_cart"
    
    logging.debug(f"An√°lise de contexto da conversa: {context_analysis}")
    return context_analysis


def get_intent(
    mensagem_usuario: str,
    dados_sessao: Dict,
    customer_context: Union[Dict, None] = None,
    cart_items_count: int = 0,
    prompt_modifier: str = "structured",
) -> Dict:
    """
    üÜï VERS√ÉO CORRIGIDA: Usa o LLM para interpretar a mensagem do usu√°rio e traduzir em uma ferramenta.
    Com fallback r√°pido para mensagens simples e timeout para evitar demoras.
    """
    try:
        logging.info(
            f"[llm_interface.py] Iniciando get_intent para mensagem: '{mensagem_usuario}'"
        )

        # üÜï MELHORA CONSCI√äNCIA CONTEXTUAL
        enhanced_context = melhorar_consciencia_contexto(mensagem_usuario, dados_sessao)
        
        # üÜï PRIORIDADE M√ÅXIMA: CNPJ em contexto de checkout
        if enhanced_context.get("is_cnpj_in_checkout_context"):
            logging.info("[llm_interface.py] CNPJ detectado em contexto de checkout")
            return {
                "tool_name": "find_customer_by_cnpj",
                "parameters": {"cnpj": mensagem_usuario.strip()}
            }
        
        # üÜï PRIORIDADE ALTA: Comandos de limpeza de carrinho
        if enhanced_context.get("limpar_carrinho_command"):
            logging.info("[llm_interface.py] Comando de limpeza de carrinho detectado")
            return {"tool_name": "limpar_carrinho", "parameters": {}}

        # Para mensagens simples, usa detec√ß√£o r√°pida sem IA
        message_lower = mensagem_usuario.lower().strip()
        
        # üÜï PRIORIDADE 1: SAUDA√á√ïES (antes de qualquer outra verifica√ß√£o)
        greeting_patterns = [
            r"^(oi|ol√°|ola)$",
            r"^(e a√≠|e ai)$", 
            r"^(bom dia|boa tarde|boa noite)$",
            r"^(boa)$"
        ]
        
        for pattern in greeting_patterns:
            if re.match(pattern, message_lower):
                logging.info("[llm_interface.py] Sauda√ß√£o detectada, usando lidar_conversa")
                return {
                    "tool_name": "lidar_conversa",
                    "parameters": {"response_text": "GENERATE_GREETING"},
                }
        
        # Outros padr√µes simples
        other_simple_patterns = [
            r"^\s*([1-9]|[1-4][0-9]|50)\s*$",  # N√∫meros 1 a 50 para sele√ß√£o de produtos
            r"^(carrinho|ver carrinho|meu carrinho)$",  # Carrinho
            r"^(finalizar|fechar|checkout)$",  # Checkout
            r"^(ajuda|help)$",  # Ajuda
            r"^(produtos|mais vendidos)$",  # Produtos populares
            r"^(mais)$",  # Mais produtos
            r"^(novo|nova)$",  # Novo pedido
        ]

        for pattern in other_simple_patterns:
            if re.match(pattern, message_lower):
                logging.info(
                    "[llm_interface.py] Mensagem simples detectada, usando fallback r√°pido"
                )
                return criar_intencao_fallback(mensagem_usuario, enhanced_context)

        # üÜï PRIORIDADE 2: BUSCA DIRETA DE PRODUTOS
        product_search_patterns = [
            r"^quero\s+\w+",      # "quero fini", "quero chocolate"
            r"^buscar\s+\w+",     # "buscar cerveja"
            r"^procurar\s+\w+",   # "procurar produto"
            r"^comprar\s+\w+",    # "comprar bala"
        ]
        
        for pattern in product_search_patterns:
            if re.match(pattern, message_lower):
                logging.info("[llm_interface.py] Busca de produto detectada, usando fallback especializado")
                return criar_intencao_fallback(mensagem_usuario, enhanced_context)
        
        # Se n√£o for habilitado uso de IA ou for mensagem muito curta, usa fallback
        if not USE_AI_FALLBACK or len(mensagem_usuario.strip()) < 3:
            return criar_intencao_fallback(mensagem_usuario, enhanced_context)

        # Carrega template do prompt
        if prompt_modifier == "direct":
            system_prompt = get_fallback_prompt()
        else:
            system_prompt = load_prompt_template()
        logging.info(
            f"[llm_interface.py] System prompt preparado. Tamanho: {len(system_prompt)} caracteres"
        )

        # Obt√©m contexto EXPANDIDO da conversa (14 mensagens para melhor contexto)
        conversation_context = obter_contexto_conversa(dados_sessao, max_messages=14)
        print(f">>> CONSOLE: Contexto da conversa com {len(dados_sessao.get('conversation_history', []))} mensagens totais")

        # Informa√ß√µes do carrinho
        cart_info = ""
        if cart_items_count > 0:
            cart_info = f"CARRINHO ATUAL: {cart_items_count} itens"
            cart_items = dados_sessao.get("shopping_cart", [])
            if cart_items:
                cart_info += " ("
                item_names = []
                for item in cart_items[:3]:  # Mostra apenas primeiros 3
                    name = item.get("descricao") or item.get(
                        "canonical_name", "Produto"
                    )
                    qt = item.get("qt", 0)
                    item_names.append(f"{name} x{qt}")
                cart_info += ", ".join(item_names)
                if len(cart_items) > 3:
                    cart_info += f" e mais {len(cart_items) - 3}"
                cart_info += ")"

        # Produtos dispon√≠veis para sele√ß√£o
        products_info = ""
        last_shown = dados_sessao.get("last_shown_products", [])
        if last_shown and enhanced_context.get("numeric_selection"):
            products_info = f"PRODUTOS MOSTRADOS RECENTEMENTE: {len(last_shown)} op√ß√µes dispon√≠veis para sele√ß√£o num√©rica"

        # Informa√ß√µes do cliente
        customer_info = ""
        if customer_context:
            customer_info = f"CLIENTE: {customer_context.get('nome', 'Identificado')}"

        # üÜï CONSTR√ìI CONTEXTO ESPEC√çFICO PARA PROBLEMAS IDENTIFICADOS
        special_context = ""
        if enhanced_context.get("limpar_carrinho_command"):
            special_context += "‚ö†Ô∏è COMANDO DE LIMPEZA DE CARRINHO DETECTADO - Use limpar_carrinho\n"
        if enhanced_context.get("is_cnpj_in_checkout_context"):
            special_context += "‚ö†Ô∏è CNPJ V√ÅLIDO EM CONTEXTO DE CHECKOUT - Use find_customer_by_cnpj\n"
        if enhanced_context.get("awaiting_cnpj"):
            special_context += "‚ö†Ô∏è BOT EST√Å ESPERANDO CNPJ PARA FINALIZAR PEDIDO\n"

        # Constr√≥i contexto completo
        full_context = f"""

MENSAGEM DO USU√ÅRIO: "{mensagem_usuario}"

{special_context}

CONTEXTO DA CONVERSA (ESSENCIAL PARA ENTENDER A SITUA√á√ÉO ATUAL):
{conversation_context}

‚ö†Ô∏è IMPORTANTE: Analise TODO o hist√≥rico acima para entender:
- O que o cliente j√° pediu ou buscou
- Onde a conversa parou
- Se h√° a√ß√µes pendentes
- O contexto da mensagem atual

ESTADO ATUAL DA SESS√ÉO:
- Carrinho: {enhanced_context.get('cart_count', 0)} itens
- Produtos mostrados: {'Sim' if enhanced_context.get('has_pending_products') else 'N√£o'}
- √öltima a√ß√£o do bot: {enhanced_context.get('last_action', 'Nenhuma')}
- Cliente identificado: {'Sim' if enhanced_context.get('customer_identified') else 'N√£o'}
- Esperando CNPJ: {'Sim' if enhanced_context.get('awaiting_cnpj') else 'N√£o'}

AN√ÅLISE CONTEXTUAL:
- Sele√ß√£o num√©rica detectada: {enhanced_context.get('numeric_selection', 'Nenhuma')}
- Quantidade inferida: {enhanced_context.get('inferred_quantity', 'N√£o especificada')}
- √â CNPJ v√°lido: {'Sim' if enhanced_context.get('is_valid_cnpj') else 'N√£o'}
- CNPJ em contexto checkout: {'Sim' if enhanced_context.get('is_cnpj_in_checkout_context') else 'N√£o'}
- Comando limpar carrinho: {'Sim' if enhanced_context.get('limpar_carrinho_command') else 'N√£o'}

COMANDOS DETECTADOS:
- Ver carrinho: {'Sim' if enhanced_context.get('direct_cart_command') else 'N√£o'}
- Finalizar: {'Sim' if enhanced_context.get('direct_checkout_command') else 'N√£o'}
- Continuar: {'Sim' if enhanced_context.get('continue_shopping') else 'N√£o'}

INSTRU√á√ïES ESPECIAIS DE ALTA PRIORIDADE:
1. ‚ö†Ô∏è Se "Comando limpar carrinho: Sim", SEMPRE use limpar_carrinho
2. ‚ö†Ô∏è Se "CNPJ em contexto checkout: Sim", SEMPRE use find_customer_by_cnpj
3. ‚ö†Ô∏è Se "Esperando CNPJ: Sim" e mensagem parece CNPJ, use find_customer_by_cnpj
4. Se h√° produtos mostrados e usu√°rio digitou n√∫mero, use adicionar_item_ao_carrinho
5. Considere TODO o hist√≥rico da conversa para interpretar a inten√ß√£o
"""

        # Prepara mensagens para o modelo
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": full_context},
        ]

        # Configura cliente Ollama
        client = ollama.Client(host=OLLAMA_HOST)

        logging.info(f"[llm_interface.py] Configurando Ollama Host: '{OLLAMA_HOST}'")

        # Tenta chamar o modelo com timeout
        start_time = time.time()
        try:
            # Faz chamada ao modelo
            response = client.chat(
                model=OLLAMA_MODEL_NAME,
                messages=messages,
                options={
                    "temperature": 0.7,  # Criativo mas consistente
                    "top_p": 0.9,
                    "num_predict": 200,  # Limite para evitar verbosidade excessiva
                    "stop": ["\n\n", "```"],  # Para em quebras duplas ou markdown
                },
                stream=False,
            )

            elapsed_time = time.time() - start_time
            logging.info(
                f"[llm_interface.py] Resposta recebida do LLM em {elapsed_time:.2f}s"
            )

            # Se demorou muito, considera usar fallback na pr√≥xima
            if elapsed_time > AI_TIMEOUT:
                logging.warning(
                    f"[llm_interface.py] LLM demorou {elapsed_time:.2f}s (timeout: {AI_TIMEOUT}s)"
                )

            # Extrai e processa resposta
            content = response.get("message", {}).get("content", "")
            logging.info(f"[llm_interface.py] Resposta do LLM: {content[:100]}...")
            
            # üîç DEBUG: Log da resposta completa para depura√ß√£o
            print(f"üîç DEBUG: Resposta completa da IA:")
            print(f"'{content}'")
            print(f"üîç Tamanho: {len(content)} caracteres")

            cleaned_content = clean_json_response(content)
            print(f"üîç DEBUG: Conte√∫do ap√≥s limpeza:")
            print(f"'{cleaned_content}'")
            logging.debug(f"[llm_interface.py] Conte√∫do limpo: {cleaned_content}")

            # Parse do JSON
            try:
                if not cleaned_content.strip():
                    print(f"üîç DEBUG: Conte√∫do vazio ap√≥s limpeza, usando fallback")
                    raise json.JSONDecodeError("Empty content", "", 0)
                    
                intent_data = json.loads(cleaned_content)
            except json.JSONDecodeError as e:
                print(f"üîç DEBUG: Erro JSON detalhado: {e}")
                if cleaned_content and len(cleaned_content) > 0:
                    print(f"üîç DEBUG: Posi√ß√£o do erro: linha {e.lineno}, coluna {e.colno}")
                    if hasattr(e, 'pos') and e.pos < len(cleaned_content):
                        start = max(0, e.pos-10)
                        end = min(len(cleaned_content), e.pos+10)
                        print(f"üîç DEBUG: Contexto do erro: '{cleaned_content[start:end]}' (posi√ß√£o {e.pos})")
                
                print(f"üîç DEBUG: IA retornou texto em vez de JSON, usando fallback")
                # Usa fallback quando JSON inv√°lido
                logging.error(f"[llm_interface.py] Erro ao parsear JSON: {e}")
                return criar_intencao_fallback(mensagem_usuario, melhorar_consciencia_contexto(mensagem_usuario, dados_sessao))
            tool_name = intent_data.get("tool_name", "lidar_conversa")

            # Valida se a ferramenta existe
            if tool_name not in AVAILABLE_TOOLS:
                logging.warning(f"[llm_interface.py] Ferramenta inv√°lida: {tool_name}")
                intent_data = {
                    "tool_name": "lidar_conversa",
                    "parameters": {
                        "response_text": "Tive um problema na consulta agora. Tentar novamente?"
                    },
                }

            # Enriquece par√¢metros com contexto adicional
            parameters = intent_data.get("parameters", {})

            # Se √© sele√ß√£o num√©rica e temos produtos, adiciona quantidade se detectada
            if (
                tool_name == "adicionar_item_ao_carrinho"
                and enhanced_context.get("numeric_selection")
                and enhanced_context.get("inferred_quantity")
            ):

                if "qt" not in parameters:
                    parameters["qt"] = enhanced_context["inferred_quantity"]

            intent_data["parameters"] = validate_intent_parameters(
                tool_name, parameters
            )

            logging.info(f"[llm_interface.py] JSON parseado com sucesso: {intent_data}")
            return intent_data

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"[llm_interface.py] Erro ao parsear JSON: {e}")
            # Fallback baseado em padr√µes simples
            return criar_intencao_fallback(mensagem_usuario, enhanced_context)

        except TimeoutError:
            logging.warning(
                f"[llm_interface.py] Timeout ao chamar LLM ap√≥s {AI_TIMEOUT}s"
            )
            return criar_intencao_fallback(mensagem_usuario, enhanced_context)

    except Exception as e:
        logging.error(f"[llm_interface.py] Erro geral: {e}", exc_info=True)
        # Usa fallback em caso de erro
        return criar_intencao_fallback(
            mensagem_usuario, melhorar_consciencia_contexto(mensagem_usuario, dados_sessao)
        )


def clean_json_response(content: str) -> str:
    """Limpa a resposta do LLM para extrair JSON v√°lido."""
    logging.debug(f"Limpando a resposta JSON: '{content[:200]}...'" )
    print(f"üîç DEBUG clean_json_response: Input = '{content[:200]}...'" )
    
    # Remove markdown se presente
    content = re.sub(r"```json\s*", "", content)
    content = re.sub(r"```\s*", "", content)

    # Procura por JSON na resposta
    json_match = re.search(r"\{.*\}", content, re.DOTALL)
    if json_match:
        extracted = json_match.group(0).strip()
        print(f"üîç DEBUG clean_json_response: JSON encontrado = '{extracted}'")
        logging.debug(f"JSON extra√≠do: '{extracted}'")
        return extracted
    
    # Se n√£o encontrou JSON, a IA provavelmente retornou texto
    print(f"üîç DEBUG clean_json_response: NENHUM JSON encontrado! Conte√∫do completo:")
    print(f"'{content}'")
    
    # Retorna string vazia para for√ßar fallback
    logging.debug("Nenhum JSON encontrado na resposta.")
    return ""


def criar_intencao_fallback(mensagem_usuario: str, contexto: Dict) -> Dict:
    """
    VERS√ÉO CORRIGIDA: Cria inten√ß√£o de fallback com l√≥gica hier√°rquica clara
    """
    logging.debug(f"Criando inten√ß√£o de fallback para a mensagem: '{mensagem_usuario}'")
    mensagem_minuscula = mensagem_usuario.lower().strip()
    estagio = contexto.get("estagio_compra", "saudacao")
    
    # ===== PRIORIDADE M√ÅXIMA: Comandos especiais =====
    
    # 1. CNPJ em contexto de checkout
    if contexto.get("cnpj_em_contexto_checkout"):
        return {
            "nome_ferramenta": "encontrar_cliente_por_cnpj",
            "parametros": {"cnpj": mensagem_usuario.strip()}
        }
    
    # 2. Comandos de limpeza de carrinho
    if contexto.get("comando_limpar_carrinho"):
        return {"nome_ferramenta": "limpar_carrinho", "parametros": {}}

    # 3. Detecta modificadores de quantidade UMA VEZ S√ì
    modificadores = detectar_modificadores_quantidade(mensagem_minuscula)
    if modificadores.get("action") == "remove":
        if contexto.get("tem_itens_carrinho"):
            return {"nome_ferramenta": "atualizar_item_carrinho", "parametros": {"acao": "remover"}}
        return {
            "nome_ferramenta": "lidar_com_conversa_casual",
            "parametros": {"texto_resposta": "Seu carrinho est√° vazio."},
        }
    elif modificadores.get("action") == "clear":
        return {"nome_ferramenta": "limpar_carrinho", "parametros": {}}

    # ===== PRIORIDADE ALTA: Sele√ß√£o num√©rica =====
    
    # 4. Sele√ß√£o num√©rica para produtos mostrados (PRIORIDADE)
    if contexto.get("selecao_numerica") and contexto.get("tem_produtos_pendentes"):
        return {
            "nome_ferramenta": "adicionar_item_ao_carrinho",
            "parametros": {
                "indice_produto": contexto.get("selecao_numerica"),
                "quantidade": contexto.get("quantidade_inferida", 1),
            },
        }
    
    # 5. Sele√ß√£o num√©rica para menu principal (L√ìGICA UNIFICADA)
    if contexto.get("selecao_numerica") and not contexto.get("tem_produtos_pendentes"):
        selecao = contexto.get("selecao_numerica")
        tem_carrinho = contexto.get("tem_itens_carrinho", False)
        
        if tem_carrinho:
            # Menu com carrinho: 1=Mais produtos, 2=Ver carrinho, 3=Finalizar
            if selecao == 1:
                return {"nome_ferramenta": "obter_produtos_mais_vendidos", "parametros": {}}
            elif selecao == 2:
                return {"nome_ferramenta": "visualizar_carrinho", "parametros": {}}
            elif selecao == 3:
                return {"nome_ferramenta": "finalizar_pedido", "parametros": {}}
        else:
            # Menu sem carrinho: 1=Ver produtos, 2=Populares, 3=Buscar
            if selecao == 1:
                return {"nome_ferramenta": "obter_produtos_mais_vendidos", "parametros": {}}
            elif selecao == 2:
                return {"nome_ferramenta": "busca_inteligente_com_promocoes", "parametros": {"termo_busca": "populares"}}
            elif selecao == 3:
                return {"nome_ferramenta": "lidar_com_conversa_casual", "parametros": {"texto_resposta": "O que voc√™ gostaria de buscar?"}}

    # ===== PRIORIDADE M√âDIA: Comandos diretos =====
    
    # 6. Comandos de carrinho
    if contexto.get("comando_carrinho_direto"):
        return {"nome_ferramenta": "visualizar_carrinho", "parametros": {}}
    
    # 7. Comandos de checkout
    if contexto.get("comando_checkout_direto"):
        return {"nome_ferramenta": "finalizar_pedido", "parametros": {}}
    
    # 8. Continuar comprando
    if contexto.get("continuar_compras"):
        return {"nome_ferramenta": "obter_produtos_mais_vendidos", "parametros": {}}

    # ===== PRIORIDADE NORMAL: Detec√ß√£o de padr√µes =====
    
    # 9. Sauda√ß√µes (UNIFICADO)
    saudacoes_exatas = ["oi", "ol√°", "ola", "e a√≠", "e ai"]
    saudacoes_expressao = ["bom dia", "boa tarde", "boa noite"]
    
    if (mensagem_minuscula in saudacoes_exatas or 
        any(saudacao in mensagem_minuscula for saudacao in saudacoes_expressao)):
        return {
            "nome_ferramenta": "lidar_com_conversa_casual",
            "parametros": {"texto_resposta": "GERAR_SAUDACAO"},
        }
    
    # 10. Busca de produtos (MELHORADA)
    palavras_chave_produto = ["quero", "buscar", "procurar", "produto", "comprar", "preciso", "tem", "vende"]
    frases_compra = ["quero comprar", "quero bala", "quero chocolate", "comprar fini"]
    
    # Prioridade para frases completas de compra
    if any(frase in mensagem_minuscula for frase in frases_compra):
        nome_produto = mensagem_minuscula
        for palavra_chave in palavras_chave_produto:
            nome_produto = nome_produto.replace(palavra_chave, "").strip()
        nome_produto = nome_produto.replace("comprar", "").strip()
        
        if nome_produto and len(nome_produto) > 1:
            return {
                "nome_ferramenta": "obter_produtos_mais_vendidos_por_nome", 
                "parametros": {"nome_produto": nome_produto},
            }
    
    # Detec√ß√£o padr√£o de busca de produtos
    if any(palavra_chave in mensagem_minuscula for palavra_chave in palavras_chave_produto):
        # Extrai nome do produto (remove palavras de comando)
        nome_produto = mensagem_minuscula
        for palavra_chave in palavras_chave_produto + ["comprar"]:
            nome_produto = nome_produto.replace(palavra_chave, "").strip()

        if nome_produto and len(nome_produto) > 1 and not contexto.get("eh_cnpj_valido"):
            return {
                "nome_ferramenta": "obter_produtos_mais_vendidos_por_nome",
                "parametros": {"nome_produto": nome_produto},
            }

    # 11. Comandos de produtos populares
    if any(palavra in mensagem_minuscula for palavra in ["produtos", "mais vendidos", "populares", "top"]):
        return {"nome_ferramenta": "obter_produtos_mais_vendidos", "parametros": {}}

    # 12. Ajuda
    if any(palavra in mensagem_minuscula for palavra in ["ajuda", "help", "como", "funciona"]):
        if estagio == "carrinho":
            texto_resposta = "Voc√™ pode digitar 'checkout' para finalizar ou informar outro produto para continuar comprando."
        elif estagio == "checkout":
            texto_resposta = "Para concluir digite 'finalizar'. Se quiser revisar os itens, digite 'carrinho'."
        else:
            texto_resposta = "Como posso te ajudar? Digite o nome de um produto que voc√™ quer buscar, 'carrinho' para ver suas compras, ou 'produtos' para ver os mais vendidos."
        return {
            "nome_ferramenta": "lidar_com_conversa_casual",
            "parametros": {"texto_resposta": texto_resposta},
        }

    # 13. Novo pedido
    if "novo" in mensagem_minuscula or "nova" in mensagem_minuscula:
        return {"nome_ferramenta": "iniciar_novo_pedido", "parametros": {}}

    # ===== FALLBACK FINAL =====
    
    # 14. Fallback padr√£o - tenta buscar o termo completo (EXCETO se for CNPJ)
    if len(mensagem_minuscula) > 2 and not contexto.get("eh_cnpj_valido"):
        return {
            "nome_ferramenta": "obter_produtos_mais_vendidos_por_nome",
            "parametros": {"nome_produto": mensagem_minuscula},
        }
    
    # 15. SE FOR CNPJ MAS N√ÉO ESTAMOS EM CONTEXTO DE CHECKOUT
    if contexto.get("eh_cnpj_valido") and not contexto.get("checkout_iniciado"):
        return {
            "nome_ferramenta": "lidar_com_conversa_casual",
            "parametros": {"texto_resposta": "Identifico que voc√™ digitou um CNPJ. Para us√°-lo, primeiro adicione itens ao carrinho e depois digite 'finalizar pedido'."},
        }
    
    # 16. Mensagens padr√£o baseadas no est√°gio
    if estagio == "carrinho":
        texto_padrao = "N√£o entendi. Voc√™ pode digitar o nome de um produto para adicionar mais itens ou 'checkout' para finalizar."
    elif estagio == "checkout":
        texto_padrao = "N√£o entendi. Digite 'finalizar' para concluir a compra ou 'carrinho' para revisar."
    elif estagio == "busca":
        texto_padrao = "N√£o entendi. Digite o nome de um produto para buscar ou 'carrinho' para ver seus itens."
    else:
        texto_padrao = "N√£o entendi. Posso mostrar os produtos mais vendidos ou buscar algo espec√≠fico."
    
    return {
        "nome_ferramenta": "lidar_com_conversa_casual",
        "parametros": {"texto_resposta": texto_padrao},
    }


def validate_intent_parameters(tool_name: str, parameters: Dict) -> Dict:
    """Valida e corrige par√¢metros da inten√ß√£o conforme a ferramenta."""
    logging.debug(f"Validando par√¢metros da inten√ß√£o para a ferramenta: '{tool_name}', Par√¢metros: {parameters}")

    if tool_name == "adicionar_item_ao_carrinho":
        # Garante que codprod seja inteiro e qt seja n√∫mero v√°lido
        if "codprod" in parameters:
            try:
                parameters["codprod"] = int(parameters["codprod"])
            except (ValueError, TypeError):
                parameters["codprod"] = 0

        if "qt" in parameters:
            try:
                qt = float(parameters["qt"])
                if qt <= 0:
                    qt = 1
                parameters["qt"] = qt
            except (ValueError, TypeError):
                parameters["qt"] = 1

    elif tool_name == "get_top_selling_products_by_name":
        # Garante que product_name seja string n√£o vazia
        if "product_name" not in parameters or not parameters["product_name"]:
            parameters["product_name"] = "produto"

        # Limita tamanho do nome do produto
        parameters["product_name"] = str(parameters["product_name"])[:100]

    elif tool_name == "atualizar_item_carrinho":
        # Valida a√ß√£o e par√¢metros relacionados
        valid_actions = ["remove", "add", "set"]
        if "acao" not in parameters or parameters["acao"] not in valid_actions:
            parameters["acao"] = "remove"
        if "quantidade" in parameters:
            try:
                qt = float(parameters["quantidade"])
                if qt <= 0:
                    qt = 1
                parameters["quantidade"] = qt
            except (ValueError, TypeError):
                parameters["quantidade"] = 1
    
    elif tool_name == "find_customer_by_cnpj":
        # üÜï VALIDA CNPJ
        cnpj = parameters.get("cnpj", "")
        # Remove caracteres especiais do CNPJ
        clean_cnpj = re.sub(r'\D', '', cnpj)
        parameters["cnpj"] = clean_cnpj

    logging.debug(f"Par√¢metros da inten√ß√£o validados: {parameters}")
    return parameters


def get_enhanced_intent(
    mensagem_usuario: str, dados_sessao: Dict, customer_context: Union[Dict, None] = None
) -> Dict:
    """Vers√£o melhorada da fun√ß√£o get_intent com valida√ß√£o adicional."""
    logging.debug(f"Obtendo inten√ß√£o aprimorada para a mensagem: '{mensagem_usuario}'")

    # Obt√©m inten√ß√£o b√°sica
    intent = get_intent(
        mensagem_usuario,
        dados_sessao,
        customer_context,
        len(dados_sessao.get("shopping_cart", [])),
    )

    if not intent:
        return criar_intencao_fallback(
            mensagem_usuario, melhorar_consciencia_contexto(mensagem_usuario, dados_sessao)
        )

    # Valida e corrige par√¢metros
    tool_name = intent.get("tool_name", "lidar_conversa")
    parameters = intent.get("parameters", {})

    validated_parameters = validate_intent_parameters(tool_name, parameters)

    intent_final = {"tool_name": tool_name, "parameters": validated_parameters}
    logging.debug(f"Inten√ß√£o aprimorada obtida: {intent_final}")
    return intent_final


def obter_intencao_rapida(mensagem_usuario: str, dados_sessao: Dict) -> Dict:
    """
    Obt√©m a inten√ß√£o do usu√°rio de forma r√°pida.

    Args:
        mensagem_usuario: A mensagem do usu√°rio.
        dados_sessao: Os dados da sess√£o.

    Returns:
        A inten√ß√£o do usu√°rio.
    """
    logging.debug(f"Obtendo inten√ß√£o r√°pida para a mensagem: '{mensagem_usuario}'")
    try:
        contexto_conversa = obter_contexto_conversa(dados_sessao)
        
        # üöÄ USA OS SISTEMAS CR√çTICOS INTEGRADOS
        historico_conversa = dados_sessao.get("historico_conversa", [])
        dados_disponiveis = {
            "produtos": dados_sessao.get("produtos_encontrados", []),
            "carrinho": dados_sessao.get("carrinho", []),
            "promocoes": dados_sessao.get("promocoes_ativas", []),
            "servicos": ["pagamento_dinheiro", "pagamento_vista"]
        }
        
        resultado_intencao = detectar_intencao_com_sistemas_criticos(
            entrada_usuario=mensagem_usuario,
            contexto_conversa=contexto_conversa,
            historico_conversa=historico_conversa,
            dados_disponiveis=dados_disponiveis
        )
        
        if resultado_intencao and "nome_ferramenta" in resultado_intencao:
            # Log com informa√ß√µes dos sistemas cr√≠ticos
            logging.info(f"[INTENT_CRITICO] Detectado: {resultado_intencao['nome_ferramenta']}, "
                        f"Coerente: {resultado_intencao.get('validacao_fluxo', {}).get('eh_coerente', 'N/A')}, "
                        f"Confuso: {resultado_intencao.get('analise_confusao', {}).get('esta_confuso', 'N/A')}, "
                        f"Redirecionamento: {resultado_intencao.get('necessita_redirecionamento', False)}")
            return resultado_intencao
            
    except Exception as e:
        logging.warning(f"[INTENT_CRITICO] Erro nos sistemas cr√≠ticos: {e}")
        # Fallback para fun√ß√£o original
        try:
            resultado_fallback = detectar_intencao_usuario_com_ia(mensagem_usuario, contexto_conversa)
            if resultado_fallback and "nome_ferramenta" in resultado_fallback:
                logging.info(f"[INTENT_FALLBACK] Usando fun√ß√£o original: {resultado_fallback['nome_ferramenta']}")
                return resultado_fallback
        except Exception as e2:
            logging.warning(f"[INTENT_FALLBACK] Erro tamb√©m na fun√ß√£o original: {e2}")
    
    # Fallback final para sistema antigo se tudo falhar
    logging.info(f"[INTENT_ULTIMO_FALLBACK] Usando sistema antigo para: {mensagem_usuario}")
    contexto = melhorar_consciencia_contexto(mensagem_usuario, dados_sessao)
    return _criar_intencao_fallback(mensagem_usuario, contexto)


def get_ai_intent_with_retry(mensagem_usuario: str, dados_sessao: Dict, max_attempts: int = 2) -> Dict:
    """
    Tenta m√∫ltiplas vezes com prompts progressivamente mais diretos
    """
    logging.debug(f"Obtendo inten√ß√£o da IA com nova tentativa para a mensagem: '{mensagem_usuario}'")
    from utils.response_parser import validate_json_structure

    for attempt in range(max_attempts):
        try:
            # Na primeira tentativa, usa o prompt padr√£o. Na segunda, um mais direto.
            prompt_modifier = "structured" if attempt == 0 else "direct"
            
            raw_response = get_intent(
                mensagem_usuario,
                dados_sessao,
                prompt_modifier=prompt_modifier
            )
            
            parsed_json = extrair_json_da_resposta_ia(raw_response)
            
            if validate_json_structure(parsed_json, AVAILABLE_TOOLS):
                logging.debug(f"Inten√ß√£o da IA obtida com sucesso na tentativa {attempt + 1}.")
                return parsed_json
                
        except Exception as e:
            logging.warning(f"Tentativa {attempt + 1} falhou: {e}")
            continue
    
    # Fallback final: an√°lise manual baseada em padr√µes
    logging.debug("N√£o foi poss√≠vel obter a inten√ß√£o da IA. Usando fallback.")
    return criar_intencao_fallback(mensagem_usuario, dados_sessao)


def generate_personalized_response(context_type: str, dados_sessao: Dict, **kwargs) -> str:
    """
    Gera respostas personalizadas e din√¢micas usando a IA para situa√ß√µes espec√≠ficas.
    
    Args:
        context_type: Tipo de contexto (error, greeting, clarification, etc.)
        dados_sessao: Dados da sess√£o para contexto
        **kwargs: Par√¢metros espec√≠ficos do contexto
    """
    logging.debug(f"Gerando resposta personalizada para o tipo de contexto: '{context_type}'")
    try:
        # Constr√≥i o contexto baseado no tipo
        conversation_history = dados_sessao.get("conversation_history", [])
        cart_items = len(dados_sessao.get("shopping_cart", []))
        
        # üÜï PROMPTS PROFISSIONAIS: Mensagens curtas, naturais mas sem inventar dados
        contexts = {
            "error": "Algo deu errado! Seja breve e amig√°vel. Diga que houve um probleminha e pe√ßa para tentar de novo. MAX 15 palavras.",
            "greeting": "Seja O PR√ìPRIO G.A.V. falando! Cumprimente de forma natural e pergunte como pode ajudar. Seja caloroso mas direto. MAX 20 palavras.",
            "clarification": "N√£o entendeu algo? Pe√ßa esclarecimento de forma natural e direta. Seja amig√°vel mas conciso. MAX 15 palavras.",
            "invalid_quantity": "Quantidade inv√°lida? Explique de forma simples e r√°pida como informar corretamente. MAX 20 palavras.",
            "invalid_selection": f"N√∫mero {kwargs.get('invalid_number', 'X')} n√£o existe! Pe√ßa para escolher entre 1 e {kwargs.get('max_options', 'N')}. SEM mencionar entrega/pagamento. MAX 12 palavras.",
            "empty_cart": "Carrinho vazio! Anime o usu√°rio a ver produtos de forma natural e entusiasmada. MAX 15 palavras.",
            "cnpj_request": "Para finalizar, preciso do seu CNPJ. Seja direto e amig√°vel, sem muita explica√ß√£o. MAX 15 palavras.",
            "operation_success": f"APENAS confirme: '{kwargs.get('success_details', '')}' ‚úÖ. PROIBIDO mencionar: entrega, cart√£o, prazos, formas de pagamento. S√≥ confirme a a√ß√£o. MAX 10 palavras.",
        }
        
        context_prompt = contexts.get(context_type, "Responda de forma natural e amig√°vel.")
        
        prompt = f"""
Voc√™ √© G.A.V. falando no WhatsApp com um cliente.

{context_prompt}

HIST√ìRICO: {conversation_history[-2:] if conversation_history else 'Primeira conversa'}
CARRINHO: {cart_items} itens

REGRAS CR√çTICAS:
- Seja VOC√ä MESMO (G.A.V.), natural e direto
- Fale como pessoa real, n√£o como rob√¥
- Use "voc√™" (nunca "voc√™s")
- Seja CONCISO - m√°ximo 2 linhas
- VARIE as palavras - n√£o seja repetitivo
- ‚ö†Ô∏è PROIBIDO ABSOLUTO: mencionar entrega, cart√£o, prazos, formas de pagamento, frete
- ‚ö†Ô∏è N√ÉO INVENTE: dados sobre servi√ßos, condi√ß√µes, detalhes n√£o fornecidos
- Seja profissional mas humano
- APENAS confirme a√ß√µes realizadas, sem adicionar informa√ß√µes extras

Responda APENAS a mensagem (sem aspas):"""

        # Faz a chamada para a IA
        response = ollama.chat(
            model=NOME_MODELO_OLLAMA,
            messages=[{"role": "user", "content": prompt}],
            options={"temperature": 0.8, "num_predict": 100}  # Mais criatividade, resposta curta
        )
        
        generated_text = response["message"]["content"].strip()
        
        # Remove aspas ou formata√ß√£o extra se houver
        generated_text = generated_text.strip('"\'')
        
        logging.info(f"[llm_interface.py] Resposta din√¢mica gerada para {context_type}: {generated_text[:50]}...")
        return generated_text
        
    except Exception as e:
        logging.error(f"[llm_interface.py] Erro ao gerar resposta personalizada: {e}")
        
        # Fallbacks individuais por contexto
        fallbacks = {
            "error": "Opa, algo deu errado aqui! Que tal voc√™ tentar de novo?",
            "greeting": "Ol√°! üëã Sou o G.A.V., Gentil Assistente de Vendas do Comercial Esperan√ßa. Como posso ajudar voc√™ hoje? üòä",
            "clarification": "N√£o consegui entender direito o que voc√™ quis dizer. Pode me explicar de novo?",
            "invalid_quantity": "N√£o entendi a quantidade que voc√™ quer. Pode me falar o n√∫mero?",
            "invalid_selection": f"Esse n√∫mero n√£o t√° na lista que te mostrei. Escolhe entre 1 e {kwargs.get('max_options', 'os n√∫meros mostrados')}!",
            "empty_cart": "Seu carrinho t√° vazio ainda! Que tal voc√™ dar uma olhada nos nossos produtos?",
            "cnpj_request": "Pra finalizar sua compra, vou precisar do seu CNPJ. Pode me passar?",
            "operation_success": "Pronto! Deu tudo certo pra voc√™!",
        }
        return fallbacks.get(context_type, "Ops, tive um probleminha. Pode tentar de novo?")


# ===== FUN√á√ïES DE COMPATIBILIDADE =====

def get_intent_fast(mensagem_usuario: str, dados_sessao: Dict) -> Dict:
    """
    Fun√ß√£o de compatibilidade para get_intent_fast (usa obter_intencao_rapida).
    CORRIGIDA: Agora passa o contexto completo da conversa para a IA.
    """
    return obter_intencao_rapida(mensagem_usuario, dados_sessao)


def melhorar_consciencia_contexto(mensagem_usuario: str, dados_sessao: Dict) -> Dict:
    """
    Fun√ß√£o de compatibilidade para melhorar_consciencia_contexto.
    """
    return melhorar_consciencia_contexto(mensagem_usuario, dados_sessao)


def _criar_intencao_fallback(mensagem_usuario: str, contexto: Dict) -> Dict:
    """
    Fun√ß√£o de compatibilidade para criar_intencao_fallback.
    """
    return criar_intencao_fallback(mensagem_usuario, contexto)
