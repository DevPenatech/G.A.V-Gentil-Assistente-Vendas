#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Classificador de Inten√ß√µes Inteligente
Usa IA para detectar automaticamente a inten√ß√£o do usu√°rio e escolher a ferramenta certa
"""

import ollama
import json
import os
import re
import time
from typing import Dict, Optional, List

from .gav_logger import log_decisao_ia


# Importa√ß√µes dos novos sistemas cr√≠ticos
from .controlador_fluxo_conversa import validar_fluxo_conversa, detectar_confusao_conversa
from .prevencao_invencao_dados import validar_resposta_ia, verificar_seguranca_resposta
from .redirecionamento_inteligente import (
    detectar_usuario_confuso,
    verificar_entrada_vazia_selecao,
)

from .gav_logger import log_decisao_ia


# Configura√ß√µes
NOME_MODELO_OLLAMA = os.getenv("OLLAMA_MODEL_NAME", "llama3.1")
HOST_OLLAMA = os.getenv("OLLAMA_HOST", "http://host.docker.internal:11434")

# Limiar padr√£o de confian√ßa para sinaliza√ß√£o
CONFIDENCE_THRESHOLD = 0.7

# Cache inteligente de inten√ß√µes para performance IA-FIRST
_cache_intencao = {}
_cache_semantico = {}  # Cache por similaridade sem√¢ntica

# Palavras-chave para cache sem√¢ntico
_palavras_chave_cache = {
    "carrinho": ["carrinho", "meu carrinho", "pedido", "itens", "cesta"],
    "cerveja": ["cerveja", "cerva", "skol", "heineken", "brahma", "antartica"],
    "finalizar_pedido": ["finalizar", "comprar", "fechar pedido", "concluir"],
    "limpar": ["limpar", "esvaziar", "zerar", "apagar", "cancelar"],
    "mais": ["mais", "continuar", "pr√≥ximos", "outros", "mostrar mais"],
    "numeros": [str(i) for i in range(1, 21)]  # N√∫meros de 1 a 20
}

def _buscar_cache_semantico(mensagem: str, contexto: str = "") -> Optional[Dict]:
    """
    Busca no cache sem√¢ntico por mensagens similares (IA-FIRST).
    Retorna inten√ß√£o cacheada se encontrar similaridade.
    """
    mensagem_lower = mensagem.lower().strip()
    
    # Se √© s√≥ n√∫mero, usa cache direto
    if mensagem_lower.isdigit():
        cache_key = f"numero_{mensagem_lower}"
        if cache_key in _cache_semantico:
            logger.debug(f"[CACHE_SEMANTICO] Hit para n√∫mero: {mensagem_lower}")
            return _cache_semantico[cache_key]
    
    # Busca por palavras-chave sem√¢nticas
    for categoria, palavras in _palavras_chave_cache.items():
        for palavra in palavras:
            if palavra in mensagem_lower:
                cache_key = f"categoria_{categoria}"
                if cache_key in _cache_semantico:
                    logger.debug(f"[CACHE_SEMANTICO] Hit para categoria: {categoria}")
                    return _cache_semantico[cache_key]
    
    return None

def _salvar_cache_semantico(mensagem: str, resultado: Dict):
    """
    Salva resultado no cache sem√¢ntico baseado em padr√µes identificados.
    """
    mensagem_lower = mensagem.lower().strip()
    
    # Cache para n√∫meros
    if mensagem_lower.isdigit():
        cache_key = f"numero_{mensagem_lower}"
        _cache_semantico[cache_key] = resultado.copy()
    
    # Cache por categoria baseado na ferramenta resultado
    ferramenta = resultado.get("nome_ferramenta", "")
    if ferramenta == "visualizar_carrinho":
        _cache_semantico["categoria_carrinho"] = resultado.copy()
    elif ferramenta == "busca_inteligente_com_promocoes":
        if any(palavra in mensagem_lower for palavra in ["cerveja", "skol", "heineken"]):
            _cache_semantico["categoria_cerveja"] = resultado.copy()
    elif ferramenta == "finalizar_pedido":
        _cache_semantico["categoria_finalizar_pedido"] = resultado.copy()
    elif ferramenta == "limpar_carrinho":
        _cache_semantico["categoria_limpar"] = resultado.copy()
    elif ferramenta == "show_more_products":
        _cache_semantico["categoria_mais"] = resultado.copy()


def _registrar_decisao(intencao: Dict):
    """Registra decis√£o da IA usando logger dedicado."""
    log_decisao_ia(
        intencao.get("nome_ferramenta", "desconhecida"),
        float(intencao.get("confidence_score", 0)),
        intencao.get("decision_strategy")
    )

def _tentar_recuperacao_inteligente_ia(mensagem_original: str, contexto: str, erro_original: str) -> Optional[Dict]:
    """
    Sistema de m√∫ltiplas tentativas inteligentes IA-FIRST.
    Tenta diferentes estrat√©gias quando a IA principal falha.
    """
    logger.info(f"[RECUPERACAO_IA] Iniciando recupera√ß√£o para: '{mensagem_original}' (erro: {erro_original})")
    
    estrategias = [
        ("mensagem_simplificada", lambda: _simplificar_mensagem_ia(mensagem_original)),
        ("contexto_reduzido", lambda: _reduzir_contexto_ia(mensagem_original, contexto)),
        ("patterns_inteligentes", lambda: _tentar_patterns_ia(mensagem_original, contexto)),
        ("fallback_contextual", lambda: _criar_fallback_contextual_ia(mensagem_original, contexto))
    ]
    
    for nome_estrategia, estrategia_func in estrategias:
        try:
            logger.debug(f"[RECUPERACAO_IA] Tentando estrat√©gia: {nome_estrategia}")
            resultado = estrategia_func()
            
            if resultado and "nome_ferramenta" in resultado:
                logger.info(f"[RECUPERACAO_IA] SUCESSO com {nome_estrategia}: {resultado['nome_ferramenta']}")
                resultado["estrategia_recuperacao"] = nome_estrategia
                resultado["recuperacao_aplicada"] = True
                return resultado
                
        except Exception as e:
            logger.debug(f"[RECUPERACAO_IA] Estrat√©gia {nome_estrategia} falhou: {e}")
            continue
    
    logger.warning("[RECUPERACAO_IA] Todas estrat√©gias falharam")
    return None

def _simplificar_mensagem_ia(mensagem: str) -> Optional[Dict]:
    """Estrat√©gia 1: Simplifica mensagem removendo ru√≠do."""
    # Remove palavras de liga√ß√£o e mant√©m s√≥ o essencial
    mensagem_limpa = re.sub(r'\b(o|a|os|as|de|da|do|em|na|no|para|por|com)\b', '', mensagem.lower())
    mensagem_limpa = re.sub(r'\s+', ' ', mensagem_limpa).strip()
    
    if mensagem_limpa and mensagem_limpa != mensagem.lower():
        try:
            import ollama
            client = ollama.Client(host=HOST_OLLAMA)
            
            prompt_simples = f"""
Classifique esta mensagem simples em UMA ferramenta:

MENSAGEM: "{mensagem_limpa}"

FERRAMENTAS DISPON√çVEIS:
- visualizar_carrinho (para "carrinho", "itens")
- busca_inteligente_com_promocoes (para buscar produtos)
- adicionar_item_ao_carrinho (para n√∫meros: 1,2,3...)
  - finalizar_pedido (para "finalizar", "comprar")
- limpar_carrinho (para "limpar", "esvaziar")
- show_more_products (para "mais")

RESPONDA APENAS EM JSON: {{"nome_ferramenta": "X", "parametros": {{}}}}
"""
            
            response = client.chat(
                model=NOME_MODELO_OLLAMA,
                messages=[{"role": "user", "content": prompt_simples}],
                options={"temperature": 0.1, "top_p": 0.3, "num_predict": 30}
            )
            
            return _extrair_json_da_resposta(response['message']['content'])
            
        except Exception as e:
            logger.debug(f"[RECUPERACAO_IA] Simplifica√ß√£o falhou: {e}")
            return None
    
    return None

def _reduzir_contexto_ia(mensagem: str, contexto: str) -> Optional[Dict]:
    """Estrat√©gia 2: Usa apenas contexto essencial."""
    # Extrai s√≥ o essencial do contexto
    contexto_reduzido = ""
    if "produtos encontrados" in contexto.lower():
        contexto_reduzido = "Lista de produtos mostrada. Escolha um n√∫mero."
    elif "carrinho" in contexto.lower():
        contexto_reduzido = "Gerenciando carrinho."
    elif "quantidade" in contexto.lower():
        contexto_reduzido = "Digite quantidade."
    
    try:
        import ollama
        client = ollama.Client(host=HOST_OLLAMA)
        
        prompt_reduzido = f"""
CONTEXTO: {contexto_reduzido}
MENSAGEM: "{mensagem}"

Qual ferramenta usar?
- Se n√∫mero e lista: adicionar_item_ao_carrinho
- Se carrinho: visualizar_carrinho  
- Se busca: busca_inteligente_com_promocoes

JSON: {{"nome_ferramenta": "X", "parametros": {{}}}}
"""
        
        response = client.chat(
            model=NOME_MODELO_OLLAMA,
            messages=[{"role": "user", "content": prompt_reduzido}],
            options={"temperature": 0.0, "num_predict": 25}
        )
        
        return _extrair_json_da_resposta(response['message']['content'])
        
    except Exception as e:
        logger.debug(f"[RECUPERACAO_IA] Contexto reduzido falhou: {e}")
        return None

def _tentar_patterns_ia(mensagem: str, contexto: str) -> Optional[Dict]:
    """Estrat√©gia 3: Usa IA para identificar padr√µes espec√≠ficos."""
    mensagem_lower = mensagem.lower().strip()
    
    # IA identifica padr√£o mais prov√°vel
    if re.match(r'^\d+$', mensagem_lower):
        return {
            "nome_ferramenta": "adicionar_item_ao_carrinho",
            "parametros": {"indice": int(mensagem_lower)}
        }
    
    elif any(palavra in mensagem_lower for palavra in ["carrinho", "itens", "pedido"]):
        return {
            "nome_ferramenta": "visualizar_carrinho",
            "parametros": {}
        }
    
    elif mensagem_lower in ["mais", "continuar", "pr√≥ximos"]:
        return {
            "nome_ferramenta": "show_more_products", 
            "parametros": {}
        }
    
    elif any(palavra in mensagem_lower for palavra in ["finalizar", "comprar", "fechar pedido"]):
        return {
            "nome_ferramenta": "finalizar_pedido",
            "parametros": {},
        }
    
    elif any(palavra in mensagem_lower for palavra in ["limpar", "esvaziar", "zerar"]):
        return {
            "nome_ferramenta": "limpar_carrinho",
            "parametros": {}
        }
    
    # Se nada funcionou, assume busca
    return {
        "nome_ferramenta": "busca_inteligente_com_promocoes",
        "parametros": {"termo_busca": mensagem}
    }

def _criar_fallback_contextual_ia(mensagem: str, contexto: str) -> Dict:
    """Estrat√©gia 4: Cria fallback inteligente baseado no contexto."""
    # An√°lise contextual simples para fallback
    if "produtos" in contexto.lower() or "lista" in contexto.lower():
        if re.match(r'^\d+$', mensagem.strip()):
            return {
                "nome_ferramenta": "adicionar_item_ao_carrinho",
                "parametros": {"indice": int(mensagem.strip())}
            }
    
    # Fallback: assume que √© busca de produto
    return {
        "nome_ferramenta": "busca_inteligente_com_promocoes",
        "parametros": {"termo_busca": mensagem},
        "fallback_contextual": True
    }


def _get_saudacao_prompt_segment() -> str:
    return (
        "üî• SAUDA√á√ïES (PRIORIDADE CR√çTICA): \"oi\", \"ol√°\", \"bom dia\", \"boa tarde\", \"boa noite\", \"eai\" ‚Üí lidar_conversa\n"
        "Agradecimentos, perguntas gerais ‚Üí lidar_conversa\n\n"
        "üî• SAUDA√á√ïES (SEMPRE DETECTAR PRIMEIRO):\n"
        "- \"oi\" ‚Üí lidar_conversa (SEMPRE, mesmo com contexto de produtos)\n"
        "- \"ol√°\" ‚Üí lidar_conversa (SEMPRE, mesmo com contexto de produtos)\n"
        "- \"bom dia\" ‚Üí lidar_conversa (SEMPRE, mesmo com contexto de produtos)\n"
        "- \"boa tarde\" ‚Üí lidar_conversa (SEMPRE, mesmo com contexto de produtos)\n"
        "- \"boa noite\" ‚Üí lidar_conversa (SEMPRE, mesmo com contexto de produtos)\n"
        "- \"eai\" ‚Üí lidar_conversa (SEMPRE, mesmo com contexto de produtos)\n"
    )


def _get_brand_prompt_segment() -> str:
    return (
        "üö® REGRA CR√çTICA PARA EVITAR CONFUS√ÉO:\n"
        "- SE A MENSAGEM CONT√âM \"FINI\" ou \"FIN√ç\" ‚Üí SEMPRE busca_inteligente_com_promocoes (marca de doces!)\n"
        "- SE A MENSAGEM CONT√âM APENAS \"FINALIZAR\" EXATA ‚Üí finalizar_pedido\n"
        "- \"deixa eu ver fini\", \"quero fini\", \"me mostra fini\" ‚Üí busca_inteligente_com_promocoes (N√ÉO finalizar!)\n"
        "- Se menciona marca comercial espec√≠fica (fini, coca-cola, omo, heineken, nutella, etc.) ‚Üí busca_inteligente_com_promocoes\n\n"
        "üéØ BUSCA POR CATEGORIA/MARCA:\n"
        "- \"quero cerveja\" ‚Üí busca_inteligente_com_promocoes (categoria de produto)\n"
        "- \"quero fini\" ‚Üí busca_inteligente_com_promocoes (marca espec√≠fica!)\n"
        "- \"deixa eu ver fini\" ‚Üí busca_inteligente_com_promocoes (marca FINI, n√£o finalizar!)\n"
        "- \"vou querer fini\" ‚Üí busca_inteligente_com_promocoes (marca FINI!)\n"
        "- \"me mostra fini\" ‚Üí busca_inteligente_com_promocoes (marca FINI!)\n"
        "- \"quero nutella\" ‚Üí busca_inteligente_com_promocoes (marca espec√≠fica!)\n"
        "- \"quero omo\" ‚Üí busca_inteligente_com_promocoes (marca espec√≠fica!)\n"
        "- \"biscoito doce\" ‚Üí obter_produtos_mais_vendidos_por_nome (produto sem marca espec√≠fica)\n"
        "- \"promo√ß√µes\" ‚Üí busca_inteligente_com_promocoes (busca por ofertas)\n\n"
        "üö® CUIDADO COM MARCAS QUE SOAM COMO \"FINALIZAR\":\n"
        "- \"deixa eu ver fini\" ‚Üí busca_inteligente_com_promocoes (marca FINI, N√ÉO finalizar!)\n"
        "- \"quero fini\" ‚Üí busca_inteligente_com_promocoes (marca FINI, N√ÉO finalizar!)\n"
        "- \"ver fini\" ‚Üí busca_inteligente_com_promocoes (marca FINI, N√ÉO finalizar!)\n"
        "- \"quero ver coca\" ‚Üí busca_inteligente_com_promocoes (marca COCA, N√ÉO finalizar!)\n\n"
        "ATEN√á√ÉO: Qualquer nome que pare√ßa ser uma marca comercial deve usar busca_inteligente_com_promocoes!\n"
    )

def detectar_intencao_usuario_com_ia(user_message: str, conversation_context: str = "") -> Dict:
    """
    Usa IA para detectar automaticamente a inten√ß√£o do usu√°rio e escolher a ferramenta apropriada.
    
    Args:
        user_message (str): Mensagem do usu√°rio a ser analisada.
        conversation_context (str, optional): Contexto da conversa para melhor an√°lise.
    
    Returns:
        Dict: Dicion√°rio contendo 'nome_ferramenta', 'parametros' e opcionalmente
        'confidence_score'. Inclui tamb√©m 'confidence_below_threshold' quando
        a confian√ßa calculada est√° abaixo de ``CONFIDENCE_THRESHOLD``.
        
    Example:
        >>> detectar_intencao_usuario_com_ia("quero cerveja")
        {"nome_ferramenta": "smart_search_with_promotions", "parametros": {"termo_busca": "quero cerveja"}}
    """
    logger.debug(f"Detectando inten√ß√£o do usu√°rio com IA para a mensagem: '{user_message}'")

    # üîÑ Limpeza peri√≥dica do cache para evitar crescimento excessivo
    if len(_cache_intencao) > 100:
        limpar_cache_intencao()

    # üöÄ CACHE SEM√ÇNTICO IA-FIRST - Tenta cache por similaridade primeiro
    cache_result = _buscar_cache_semantico(user_message, conversation_context)
    if cache_result:
        logging.info(f"[CACHE
        score = cache_result.get("confidence_score", 0.0)
        cache_result["confidence_below_threshold"] = score < CONFIDENCE_THRESHOLD
        log_decisao_ia(cache_result.get("nome_ferramenta", "unknown"), score, cache_result.get("decision_strategy"))

        return cache_result
    
    # Cache exato (mantido para compatibilidade)
    cache_key = user_message.lower().strip()
    if not conversation_context and cache_key in _cache_intencao:

        logging.debug(f"[INTENT] Cache exato hit para: {cache_key}")
        resultado_cache = _cache_intencao[cache_key]
        score = resultado_cache.get("confidence_score", 0.0)
        resultado_cache["confidence_below_threshold"] = score < CONFIDENCE_THRESHOLD
        log_decisao_ia(resultado_cache.get("nome_ferramenta", "unknown"), score, resultado_cache.get("decision_strategy"))
        return resultado_cache
    

    try:
        # Prompt otimizado para detec√ß√£o de inten√ß√£o COM CONTEXTO COMPLETO
        brand_segment = _get_brand_prompt_segment()
        log_prompt_completo(brand_segment, funcao="detectar_intencao_usuario_com_ia", segmento="marcas")
        saudacao_segment = _get_saudacao_prompt_segment()
        log_prompt_completo(saudacao_segment, funcao="detectar_intencao_usuario_com_ia", segmento="saudacoes")
        intent_prompt = f"""
Voc√™ √© um classificador de inten√ß√µes para um assistente de vendas do WhatsApp.

FERRAMENTAS DISPON√çVEIS:
1. busca_inteligente_com_promocoes - Para busca por categoria ou promo√ß√µes espec√≠ficas
2. mostrar_todas_promocoes - Para ver TODAS promo√ß√µes organizadas por categoria
3. obter_produtos_mais_vendidos_por_nome - Para busca de produto espec√≠fico
4. atualizacao_inteligente_carrinho - Para modificar carrinho (adicionar/remover)
5. visualizar_carrinho - Para ver carrinho
6. limpar_carrinho - Para limpar carrinho
7. adicionar_item_ao_carrinho - Para selecionar item por n√∫mero
8. show_more_products - Para mostrar mais produtos da mesma busca (palavra: mais)
9. finalizar_pedido - Para finalizar pedido (palavras: finalizar, comprar)
10. handle_chitchat - Para sauda√ß√µes e conversas que resetam estado
11. lidar_conversa - Para conversas gerais que mant√™m contexto


CONTEXTO DA CONVERSA (FUNDAMENTAL PARA AN√ÅLISE):
{conversation_context if conversation_context else "Primeira intera√ß√£o"}

MENSAGEM ATUAL DO USU√ÅRIO: "{user_message}"

REGRAS DE CLASSIFICA√á√ÉO (ANALISE O CONTEXTO ANTES DE DECIDIR):

{brand_segment}
1. PRIMEIRO, analise o CONTEXTO da conversa para entender a situa√ß√£o atual
2. Se o bot mostrou uma lista de produtos e o usu√°rio responde com n√∫mero ‚Üí adicionar_item_ao_carrinho
3. üöÄ CR√çTICO: Se usu√°rio diz apenas "mais" ap√≥s uma busca de produtos ‚Üí show_more_products
4. üéØ NOVO: Se usu√°rio quer ver "promo√ß√µes", "produtos em promo√ß√£o", "ofertas" (gen√©rico, sem categoria espec√≠fica) ‚Üí mostrar_todas_promocoes
5. Se o usu√°rio quer buscar categoria (cerveja, limpeza, comida, etc.) ‚Üí busca_inteligente_com_promocoes
6. Se menciona "promo√ß√£o", "oferta", "desconto" ‚Üí busca_inteligente_com_promocoes
7. Se busca produto gen√©rico sem marca espec√≠fica (ex: "biscoito doce", "shampoo qualquer") ‚Üí obter_produtos_mais_vendidos_por_nome
8. Se fala "adiciona", "coloca", "mais", "remove", "remover", "tirar" com produto ‚Üí atualizacao_inteligente_carrinho
9. Se pergunta sobre carrinho ou quer ver carrinho ‚Üí visualizar_carrinho
10. Se quer limpar/esvaziar carrinho ‚Üí limpar_carrinho

{saudacao_segment}
OUTROS EXEMPLOS (ANALISE SEMPRE O CONTEXTO PRIMEIRO):
- "mais" ‚Üí show_more_products (PRIORIDADE M√ÅXIMA ap√≥s busca!)
- "mais produtos" ‚Üí show_more_products (continuar busca)
- "continuar" ‚Üí show_more_products (mostrar mais produtos)

üõí CARRINHO:
- "limpar carrinho" ‚Üí limpar_carrinho (comando para esvaziar carrinho)
- "esvaziar carrinho" ‚Üí limpar_carrinho (comando para limpar carrinho)
- "zerar carrinho" ‚Üí limpar_carrinho (comando para resetar carrinho)
- "ver carrinho" ‚Üí visualizar_carrinho (comando para mostrar carrinho)
- "adicionar 2 skol" ‚Üí atualizacao_inteligente_carrinho (adicionar produto com quantidade)
- "remover 1 skol" ‚Üí atualizacao_inteligente_carrinho (remover produto com quantidade)
- "tirar cerveja" ‚Üí atualizacao_inteligente_carrinho (remover produto do carrinho)

üî• FINALIZA√á√ÉO DE PEDIDO (APENAS ESTAS PALAVRAS EXATAS):
- "finalizar" ‚Üí finalizar_pedido (APENAS palavra exata "finalizar")
- "finalizar pedido" ‚Üí finalizar_pedido (APENAS frase exata)
- "comprar" ‚Üí finalizar_pedido (APENAS palavra exata "comprar")
- "confirmar pedido" ‚Üí finalizar_pedido (APENAS frase exata)

IMPORTANT√çSSIMO: Use o CONTEXTO para entender se o usu√°rio est√° respondendo a uma pergunta do bot!

PAR√ÇMETROS ESPERADOS:
- busca_inteligente_com_promocoes: {{"termo_busca": "termo_completo"}}
- obter_produtos_mais_vendidos_por_nome: {{"nome_produto": "nome_produto"}}
- adicionar_item_ao_carrinho: {{"indice": numero}}
- atualizacao_inteligente_carrinho: {{"nome_produto": "produto", "acao": "add/remove/set", "quantidade": numero}}
- lidar_conversa: {{"response_text": "resposta_natural"}}

ATEN√á√ÉO ESPECIAL PARA A√á√ïES:
- "adicionar", "colocar", "mais" ‚Üí acao: "add"
- "remover", "tirar", "remove" ‚Üí acao: "remove"
- "trocar para", "mudar para" ‚Üí acao: "set"

üö® IMPORTANTE: RESPONDA APENAS EM JSON V√ÅLIDO, SEM EXPLICA√á√ïES!

EXEMPLOS DE RESPOSTA CORRETA:
Para sauda√ß√µes: {{"nome_ferramenta": "lidar_conversa", "parametros": {{"response_text": "GENERATE_GREETING"}}}}
Para mais produtos: {{"nome_ferramenta": "show_more_products", "parametros": {{}}}}

üî• N√ÉO ESCREVA TEXTO EXPLICATIVO! APENAS JSON!
"""
        log_prompt_completo(intent_prompt, funcao="detectar_intencao_usuario_com_ia", segmento="completo")

        logger.debug(f"[INTENT] Classificando inten√ß√£o para: {user_message}")
        
        client = ollama.Client(host=HOST_OLLAMA)
        response = client.chat(
            model=NOME_MODELO_OLLAMA,
            messages=[
                {"role": "system", "content": "Voc√™ DEVE responder APENAS em JSON v√°lido. N√ÉO escreva explica√ß√µes."},
                {"role": "user", "content": intent_prompt}
            ],
            options={
                "temperature": 0.0,  # Zero para m√°ximo determinismo
                "top_p": 0.1,
                "num_predict": 50,  # Menos tokens para for√ßar JSON conciso
                "stop": ["\n\n", "**", "An√°lise"]  # Para parar se come√ßar a explicar
            }
        )
        
        ai_response = response['message']['content'].strip()

        logger.debug(f">>> [CLASSIFICADOR_IA] Mensagem: '{user_message}'")
        logger.debug(f">>> [CLASSIFICADOR_IA] IA respondeu: {ai_response}")
        
        # Extrai JSON da resposta
        intent_data = _extrair_json_da_resposta(ai_response)
        logger.debug(f">>> [CLASSIFICADOR_IA] JSON extra√≠do: {intent_data}")

        
        if intent_data and "nome_ferramenta" in intent_data:
            # Valida se a ferramenta existe
            ferramentas_validas = [
                "busca_inteligente_com_promocoes",
                "obter_produtos_mais_vendidos_por_nome", 
                "atualizacao_inteligente_carrinho",
                "visualizar_carrinho",
                "limpar_carrinho", 
                "adicionar_item_ao_carrinho",
                "show_more_products",
                "finalizar_pedido",
                "handle_chitchat",
                "lidar_conversa"
            ]
            
            if intent_data["nome_ferramenta"] in ferramentas_validas:
                # üöÄ NOVO: Sistema de Valida√ß√£o Proativa de Par√¢metros
                intent_data = _parameter_validator.pre_validate_intent(
                    intent_data, user_message, conversation_context
                )
                
                # üöÄ Sistema de Confian√ßa e Score de Decis√£o
                confidence_score = _confidence_system.analyze_intent_confidence(
                    intent_data, user_message, conversation_context
                )
                decision_strategy = _confidence_system.get_decision_strategy(confidence_score)
                
                # Adiciona dados de confian√ßa ao resultado
                intent_data["confidence_score"] = confidence_score
                intent_data["decision_strategy"] = decision_strategy

                intent_data["confidence_below_threshold"] = confidence_score < CONFIDENCE_THRESHOLD

                log_decisao_ia(
                    intent_data.get("nome_ferramenta", "unknown"),
                    confidence_score,
                    decision_strategy,
                )

                logging.info(
                    f"[INTENT] Inten√ß√£o: {intent_data['nome_ferramenta']}, "
                    f"Confian√ßa: {confidence_score:.3f}, "
                    f"Estrat√©gia: {decision_strategy}, "
                    f"Valida√ß√£o: {intent_data.get('validation_status', 'N/A')}")

                
                # Cache apenas se n√£o h√° contexto (primeira intera√ß√£o)
                if not conversation_context:
                    _cache_intencao[cache_key] = intent_data

                # üöÄ CACHE SEM√ÇNTICO IA-FIRST - Salva sempre no cache sem√¢ntico
                _salvar_cache_semantico(user_message, intent_data)

                return intent_data
        
        # üöÄ M√öLTIPLAS TENTATIVAS IA-FIRST - Se IA falhou, tenta recupera√ß√£o inteligente
        logger.warning(f"[INTENT] IA n√£o retornou inten√ß√£o v√°lida, tentando recupera√ß√£o inteligente")
        recuperacao_result = _tentar_recuperacao_inteligente_ia(user_message, conversation_context, "json_invalido")
        if recuperacao_result:
            score = recuperacao_result.get("confidence_score", 0.0)
            recuperacao_result["confidence_below_threshold"] = score < CONFIDENCE_THRESHOLD
            log_decisao_ia(recuperacao_result.get("nome_ferramenta", "unknown"), score, recuperacao_result.get("decision_strategy"))
            # Salva no cache sem√¢ntico o resultado recuperado
            _salvar_cache_semantico(user_message, recuperacao_result)
            _registrar_decisao(recuperacao_result)
            return recuperacao_result

        logging.warning(f"[INTENT] Recupera√ß√£o falhou, usando fallback final")
        fallback = _criar_intencao_fallback(user_message, conversation_context)
        _registrar_decisao(fallback)
        return fallback

        
    except Exception as e:
        logger.error(f"[INTENT] Erro na detec√ß√£o de inten√ß√£o: {e}")
        
        # üöÄ M√öLTIPLAS TENTATIVAS IA-FIRST - Mesmo com erro, tenta recupera√ß√£o
        try:
            recuperacao_result = _tentar_recuperacao_inteligente_ia(user_message, conversation_context, str(e))
            if recuperacao_result:
                logging.info(f"[RECUPERACAO_IA] Recupera√ß√£o bem-sucedida ap√≥s erro: {recuperacao_result['nome_ferramenta']}")
                score = recuperacao_result.get("confidence_score", 0.0)
                recuperacao_result["confidence_below_threshold"] = score < CONFIDENCE_THRESHOLD
                log_decisao_ia(recuperacao_result.get("nome_ferramenta", "unknown"), score, recuperacao_result.get("decision_strategy"))

                _salvar_cache_semantico(user_message, recuperacao_result)
                _registrar_decisao(recuperacao_result)
                return recuperacao_result
        except Exception as e2:

            logging.debug(f"[RECUPERACAO_IA] Recupera√ß√£o tamb√©m falhou: {e2}")

        fallback = _criar_intencao_fallback(user_message, conversation_context)
        _registrar_decisao(fallback)
        return fallback


def _extrair_json_da_resposta(response: str) -> Optional[Dict]:
    """
    Extrai dados JSON da resposta da IA.
    
    Args:
        response (str): Resposta da IA para an√°lise.
    
    Returns:
        Optional[Dict]: Dados JSON extra√≠dos ou None se n√£o encontrados.
    """
    logger.debug(f"Extraindo JSON da resposta da IA: '{response}'")
    try:
        # Procura por JSON na resposta
        json_pattern = r'\{.*?\}'
        matches = re.findall(json_pattern, response, re.DOTALL)
        
        for match in matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue
        
        # Se n√£o encontrou JSON, tenta a resposta inteira
        return json.loads(response)
        
    except Exception as e:
        logger.debug(f"[INTENT] Erro ao extrair JSON: {e}")
        return None

def _criar_intencao_fallback(user_message: str, conversation_context: str = "") -> Dict:
    """
    Cria inten√ß√£o de fallback baseada em regras simples quando a IA falha.
    
    Args:
        user_message (str): Mensagem do usu√°rio para an√°lise.
    
    Returns:
        Dict: Inten√ß√£o de fallback com nome_ferramenta e parametros.
    """
    logger.debug(f"Criando inten√ß√£o de fallback para a mensagem: '{user_message}'")
    
    message_lower = user_message.lower().strip()
    
    def _add_confidence_to_intent(intent_data: Dict) -> Dict:
        """Adiciona valida√ß√£o e dados de confian√ßa a qualquer inten√ß√£o."""
        # Aplica valida√ß√£o
        intent_data = _parameter_validator.pre_validate_intent(
            intent_data, user_message, conversation_context
        )
        
        # Calcula confian√ßa
        confidence_score = _confidence_system.analyze_intent_confidence(
            intent_data, user_message, conversation_context
        )
        decision_strategy = _confidence_system.get_decision_strategy(confidence_score)
        below_threshold = confidence_score < CONFIDENCE_THRESHOLD

        intent_data["confidence_score"] = confidence_score
        intent_data["decision_strategy"] = decision_strategy

        intent_data["confidence_below_threshold"] = below_threshold

        log_decisao_ia(
            intent_data.get("nome_ferramenta", "unknown"),
            confidence_score,
            decision_strategy,
        )

        logging.debug(
            f"[FALLBACK] {intent_data['nome_ferramenta']}: "
            f"confian√ßa={confidence_score:.3f}, estrat√©gia={decision_strategy}, "
            f"valida√ß√£o={intent_data.get('validation_status', 'N/A')}")

        return intent_data
    
    # Regras de fallback simples com CONTEXTO IA-FIRST
    if re.match(r'^\d+$', message_lower):
        # PRIMEIRO: Verifica se h√° a√ß√£o pendente de atualiza√ß√£o inteligente 
        if "AWAITING_SMART_UPDATE_SELECTION" in conversation_context:
            return _add_confidence_to_intent({
                "nome_ferramenta": "selecionar_item_para_atualizacao",
                "parametros": {"indice": int(message_lower)}
            })
        # SEGUNDO: Verifica se √© resposta √† op√ß√£o de finalizar pedido
        elif ("Finalizar Pedido" in conversation_context and user_message.strip() == "1"):
            return _add_confidence_to_intent({
                "nome_ferramenta": "finalizar_pedido",
                "parametros": {},
            })
        else:
            return _add_confidence_to_intent({
                "nome_ferramenta": "adicionar_item_ao_carrinho", 
                "parametros": {"indice": int(message_lower)}
            })
    
    # PRIMEIRA PRIORIDADE: A√ß√µes espec√≠ficas de carrinho (deve vir ANTES da verifica√ß√£o gen√©rica de 'carrinho')
    if any(word in message_lower for word in ['adiciona', 'coloca', 'mais', 'remove', 'remover', 'tirar', 'trocar', 'mudar', 'alterar']):
        # Detecta a a√ß√£o correta com IA-FIRST
        if any(word in message_lower for word in ['remove', 'remover', 'tirar', 'tira']):
            acao = "remove"
        elif any(word in message_lower for word in ['trocar', 'mudar', 'alterar']) and 'para' in message_lower:
            acao = "set"  # Para definir quantidade espec√≠fica
        else:
            acao = "add"
        
        # Extrai quantidade de n√∫meros na mensagem
        quantidade = 1
        numeros = re.findall(r'\d+', user_message)
        if numeros:
            quantidade = int(numeros[0])
        
        # Limpa nome do produto removendo a√ß√µes, n√∫meros e refer√™ncias ao carrinho
        nome_produto = user_message
        palavras_para_remover = ['remover', 'remove', 'tirar', 'tira', 'adicionar', 'adiciona', 'coloca', 'mais', 'trocar', 'mudar', 'alterar', 'para', 'carrinho', 'no', 'do', 'da', 'ao', 'na']
        for palavra in palavras_para_remover:
            nome_produto = re.sub(rf'\b{palavra}\b', '', nome_produto, flags=re.IGNORECASE)
        nome_produto = re.sub(r'\d+', '', nome_produto)  # Remove n√∫meros
        nome_produto = re.sub(r'\s+', ' ', nome_produto).strip()  # Limpa espa√ßos extras
        
        return _add_confidence_to_intent({
            "nome_ferramenta": "atualizacao_inteligente_carrinho",
            "parametros": {"acao": acao, "quantidade": quantidade, "nome_produto": nome_produto}
        })
    
    # SEGUNDA PRIORIDADE: Comandos de finaliza√ß√£o de pedido (PRIORIDADE ALTA - limpa estado pendente)
    if any(word in message_lower for word in ['finalizar', 'concluir', 'fechar pedido', 'comprar', 'finalizar pedido']):
        return _add_confidence_to_intent({
            "nome_ferramenta": "finalizar_pedido",
            "parametros": {"force_finalizar_pedido": True}  # For√ßa finaliza√ß√£o independente do estado
        })
    
    # TERCEIRA PRIORIDADE: Comandos de limpeza de carrinho
    if any(word in message_lower for word in ['limpar', 'esvaziar', 'zerar']):
        return _add_confidence_to_intent({
            "nome_ferramenta": "limpar_carrinho",
            "parametros": {}
        })
    
    # QUARTA PRIORIDADE: Visualizar carrinho (somente quando n√£o h√° a√ß√£o espec√≠fica)  
    if any(word in message_lower for word in ['carrinho', 'meu carrinho']) and not any(word in message_lower for word in ['adiciona', 'coloca', 'mais', 'remove', 'remover', 'tirar', 'limpar', 'esvaziar', 'zerar']):
        return _add_confidence_to_intent({
            "nome_ferramenta": "visualizar_carrinho", 
            "parametros": {}
        })
    
    # Detecta se √© busca por categoria ou promo√ß√£o
    palavras_categoria = [
        'cerveja', 'bebida', 'refrigerante', 'suco',
        'limpeza', 'detergente', 'sab√£o', 
        'higiene', 'shampoo', 'sabonete',
        'comida', 'alimento', 'arroz', 'feij√£o',
        'promo√ß√£o', 'oferta', 'desconto', 'barato'
    ]
    
    # üÜï IA-FIRST: Detecta automaticamente se √© uma marca conhecida usando IA
    def _detectar_marca_com_ia(mensagem: str) -> bool:
        """Usa IA para detectar se a mensagem cont√©m uma marca conhecida."""
        logger.debug(f"Detectando marca com IA para a mensagem: '{mensagem}'")
        try:
            import ollama
            prompt_marca = f"""Analise se esta mensagem cont√©m uma MARCA ESPEC√çFICA de produto comercial:

MENSAGEM: "{mensagem}"

MARCAS ESPEC√çFICAS S√ÉO:
- Nomes comerciais conhecidos de empresas/fabricantes
- Exemplos: coca-cola, fini, omo, heineken, dove, nutella, skol, pantene
- Palavras que soam como nomes de marca comercial

N√ÉO S√ÉO MARCAS:
- Categorias de produtos: cerveja, doce, sab√£o, refrigerante
- Descri√ß√µes gen√©ricas: biscoito doce, √°gua gelada
- Tipos de produto: shampoo, detergente (sem nome espec√≠fico)

Se a mensagem menciona qualquer palavra que pode ser uma marca comercial, responda SIM.
Se √© apenas categoria ou descri√ß√£o gen√©rica, responda NAO.

RESPONDA APENAS: SIM ou NAO"""

            client = ollama.Client(host=HOST_OLLAMA)
            response = client.chat(
                model=NOME_MODELO_OLLAMA,
                messages=[{"role": "user", "content": prompt_marca}],
                options={"temperature": 0.1, "top_p": 0.3, "num_predict": 10}
            )
            
            resposta = response['message']['content'].strip().upper()
            resultado = "SIM" in resposta
            logger.debug(f"[IA-MARCA] '{mensagem}' ‚Üí IA disse: '{resposta}' ‚Üí resultado: {resultado}")
            return resultado
        except Exception as e:
            logger.warning(f"[IA-MARCA] Erro na detec√ß√£o para '{mensagem}': {e}")
            # Fallback: se IA falhar, assume que √© marca se n√£o for categoria √≥bvia
            palavras_categoria_obvias = ['cerveja', 'refrigerante', 'doce', 'bala', 'sab√£o', 'detergente']
            fallback_resultado = not any(cat in mensagem.lower() for cat in palavras_categoria_obvias)
            logger.debug(f"[IA-MARCA] Fallback para '{mensagem}': {fallback_resultado}")
            return fallback_resultado
    
    # Se cont√©m categoria ou √© marca detectada pela IA, usa busca inteligente
    if (any(keyword in message_lower for keyword in palavras_categoria) or
        _detectar_marca_com_ia(user_message)):
        return _add_confidence_to_intent({
            "nome_ferramenta": "busca_inteligente_com_promocoes",
            "parametros": {"termo_busca": user_message}
        })
    
    # Sauda√ß√µes e conversas gerais
    saudacoes = ['oi', 'ol√°', 'boa', 'como', 'obrigado', 'tchau']
    if any(greeting in message_lower for greeting in saudacoes):
        return _add_confidence_to_intent({
            "nome_ferramenta": "lidar_conversa",
            "parametros": {"texto_resposta": "Ol√°! Como posso te ajudar hoje?"}
        })
    
    # Default: busca por produto espec√≠fico
    fallback_intent = {
        "nome_ferramenta": "obter_produtos_mais_vendidos_por_nome",
        "parametros": {"nome_produto": user_message}
    }
    
    # Aplica valida√ß√£o ao fallback tamb√©m
    fallback_intent = _parameter_validator.pre_validate_intent(
        fallback_intent, user_message, conversation_context
    )
    
    # Adiciona confian√ßa ao fallback (geralmente menor)
    confidence_score = _confidence_system.analyze_intent_confidence(
        fallback_intent, user_message, conversation_context
    )
    decision_strategy = _confidence_system.get_decision_strategy(confidence_score)
    
    fallback_intent["confidence_score"] = confidence_score
    fallback_intent["decision_strategy"] = decision_strategy
    
    logger.info(f"[FALLBACK] Inten√ß√£o: {fallback_intent['nome_ferramenta']}, "
               f"Confian√ßa: {confidence_score:.3f}, "
               f"Estrat√©gia: {decision_strategy}, "
               f"Valida√ß√£o: {fallback_intent.get('validation_status', 'N/A')}")
    
    return fallback_intent

def limpar_cache_intencao():
    """
    Limpa o cache de inten√ß√µes para liberar mem√≥ria.
    
    Note:
        Deve ser chamada periodicamente para evitar ac√∫mulo excessivo de cache.
    """
    global _cache_intencao
    _cache_intencao.clear()
    logger.info("[INTENT] Cache de inten√ß√µes limpo")

def obter_estatisticas_intencao() -> Dict:
    """
    Retorna estat√≠sticas do classificador de inten√ß√µes.
    
    Returns:
        Dict: Estat√≠sticas contendo tamanho do cache e inten√ß√µes armazenadas.
        
    Example:
        >>> obter_estatisticas_intencao()
        {"tamanho_cache": 5, "intencoes_cache": ["oi", "carrinho"]}
    """
    logger.debug("Obtendo estat√≠sticas do classificador de inten√ß√µes.")
    return {
        "tamanho_cache": len(_cache_intencao),
        "intencoes_cache": list(_cache_intencao.keys())[:10]  # Mostra primeiras 10
    }


class IntentConfidenceSystem:
    """
    Sistema de Confian√ßa e Score de Decis√£o para melhorar precis√£o da IA.
    
    Calcula score de confian√ßa 0.0-1.0 baseado em m√∫ltiplos fatores para 
    decidir estrat√©gia de execu√ß√£o (imediata, valida√ß√£o, confirma√ß√£o ou fallback).
    """
    
    def __init__(self):
        # Hist√≥rico de sucesso por ferramenta (ser√° alimentado ao longo do tempo)
        self._historical_success = {
            "busca_inteligente_com_promocoes": 0.85,
            "obter_produtos_mais_vendidos_por_nome": 0.80,
            "atualizacao_inteligente_carrinho": 0.75,
            "visualizar_carrinho": 0.95,
            "limpar_carrinho": 0.95,
            "adicionar_item_ao_carrinho": 0.90,
            "show_more_products": 0.85,
            "finalizar_pedido": 0.70,
            "handle_chitchat": 0.90,
            "lidar_conversa": 0.85

        }
        
    def analyze_intent_confidence(self, intent_data: Dict, user_message: str, context: str = "") -> float:
        """
        Calcula score de confian√ßa 0.0-1.0 baseado em m√∫ltiplos fatores.
        
        Args:
            intent_data: Dados da inten√ß√£o detectada pela IA
            user_message: Mensagem original do usu√°rio
            context: Contexto da conversa
            
        Returns:
            float: Score de confian√ßa entre 0.0-1.0
        """
        logger.debug(f"[CONFIDENCE] Analisando confian√ßa para: {intent_data.get('nome_ferramenta', 'unknown')}")
        
        confidence_factors = {
            "context_alignment": self._check_context_match(intent_data, context),
            "parameter_completeness": self._validate_parameters_completeness(intent_data),
            "conversation_flow": self._analyze_conversation_flow(context, user_message),
            "linguistic_patterns": self._analyze_linguistic_confidence(intent_data, user_message),
            "historical_success": self._get_historical_success_rate(intent_data.get("nome_ferramenta", ""))
        }
        
        # Pesos para cada fator (soma = 1.0)
        weights = {
            "context_alignment": 0.25,
            "parameter_completeness": 0.20,
            "conversation_flow": 0.20,
            "linguistic_patterns": 0.20,
            "historical_success": 0.15
        }
        
        # Calcula m√©dia ponderada
        confidence = sum(confidence_factors[factor] * weights[factor] 
                        for factor in confidence_factors)
        
        logger.debug(f"[CONFIDENCE] Fatores: {confidence_factors}")
        logger.debug(f"[CONFIDENCE] Score final: {confidence:.3f}")
        
        return round(confidence, 3)
    
    def get_decision_strategy(self, confidence: float) -> str:
        """
        Determina estrat√©gia de execu√ß√£o baseada no score de confian√ßa.
        
        Args:
            confidence: Score de confian√ßa 0.0-1.0
            
        Returns:
            str: Estrat√©gia de execu√ß√£o
        """
        if confidence >= 0.9:
            return "execute_immediately"      # 0.9-1.0: Execute imediatamente
        elif confidence >= 0.7:
            return "execute_with_validation"  # 0.7-0.9: Execute com valida√ß√£o
        elif confidence >= 0.5:
            return "ask_confirmation"         # 0.5-0.7: Pe√ßa confirma√ß√£o
        else:
            return "use_smart_fallback"       # 0.0-0.5: Use fallback inteligente
    
    def _check_context_match(self, intent_data: Dict, context: str) -> float:
        """Verifica alinhamento com contexto da conversa."""
        if not context:
            return 0.7  # Neutro se n√£o h√° contexto
            
        tool_name = intent_data.get("nome_ferramenta", "")
        
        # Verifica padr√µes contextuais espec√≠ficos
        if "lista de produtos" in context.lower() or "produtos encontrados" in context.lower():
            if tool_name == "adicionar_item_ao_carrinho":
                return 0.95  # Alta confian√ßa para sele√ß√£o ap√≥s listagem
            elif tool_name in ["busca_inteligente_com_promocoes", "obter_produtos_mais_vendidos_por_nome"]:
                return 0.6   # M√©dia confian√ßa, pode ser nova busca
        
        if "carrinho" in context.lower():
            if tool_name in ["visualizar_carrinho", "atualizacao_inteligente_carrinho", "limpar_carrinho"]:
                return 0.9   # Alta confian√ßa para a√ß√µes de carrinho
        
        if "finalizar" in context.lower() or "finalizar_pedido" in context.lower():
            if tool_name == "finalizar_pedido":
                return 0.95  # Alta confian√ßa para finaliza√ß√£o
        
        return 0.75  # Confian√ßa m√©dia por padr√£o
    
    def _validate_parameters_completeness(self, intent_data: Dict) -> float:
        """Verifica completude e qualidade dos par√¢metros."""
        parametros = intent_data.get("parametros", {})
        tool_name = intent_data.get("nome_ferramenta", "")
        
        # Ferramentas que n√£o precisam de par√¢metros espec√≠ficos
        no_params_tools = ["visualizar_carrinho", "limpar_carrinho", "show_more_products"]
        if tool_name in no_params_tools:
            return 0.95
        
        # Verifica par√¢metros obrigat√≥rios por ferramenta
        required_params = {
            "busca_inteligente_com_promocoes": ["termo_busca"],
            "obter_produtos_mais_vendidos_por_nome": ["nome_produto"], 
            "atualizacao_inteligente_carrinho": ["acao"],
            "adicionar_item_ao_carrinho": ["indice"],
            "lidar_conversa": ["response_text"]
        }
        
        required = required_params.get(tool_name, [])
        if not required:
            return 0.8  # Ferramenta n√£o reconhecida
        
        # Verifica se todos os par√¢metros obrigat√≥rios est√£o presentes e n√£o vazios
        missing_params = []
        for param in required:
            if param not in parametros or not str(parametros[param]).strip():
                missing_params.append(param)
        
        if not missing_params:
            return 0.95  # Todos par√¢metros presentes
        elif len(missing_params) < len(required):
            return 0.6   # Alguns par√¢metros faltando
        else:
            return 0.3   # Muitos par√¢metros faltando
    
    def _analyze_conversation_flow(self, context: str, user_message: str) -> float:
        """Analisa flu√™ncia da conversa e transi√ß√£o entre inten√ß√µes."""
        if not context:
            return 0.8  # Primeira intera√ß√£o
        
        # Detecta padr√µes de flu√™ncia conversacional
        user_lower = user_message.lower().strip()
        
        # Respostas simples/diretas t√™m alta confian√ßa
        if re.match(r'^\d+$', user_lower):  # N√∫meros isolados
            return 0.95
        
        if user_lower in ['sim', 'n√£o', 'ok', 'beleza', 'certo']:
            return 0.9  # Confirma√ß√µes simples
        
        # Comandos diretos t√™m alta confian√ßa
        direct_commands = ['carrinho', 'limpar', 'finalizar', 'mais']
        if any(cmd in user_lower for cmd in direct_commands):
            return 0.85
        
        # Perguntas diretas t√™m boa confian√ßa
        if user_message.strip().endswith('?'):
            return 0.8
        
        return 0.75  # Confian√ßa m√©dia por padr√£o
    
    def _analyze_linguistic_confidence(self, intent_data: Dict, user_message: str) -> float:
        """Analisa confian√ßa baseada em padr√µes lingu√≠sticos."""
        user_lower = user_message.lower().strip()
        tool_name = intent_data.get("nome_ferramenta", "")
        
        # Palavras-chave que indicam alta confian√ßa para cada ferramenta
        high_confidence_patterns = {
            "visualizar_carrinho": ["carrinho", "meu carrinho", "ver carrinho"],
            "limpar_carrinho": ["limpar", "esvaziar", "zerar", "apagar"],
            "finalizar_pedido": ["finalizar", "comprar", "fechar pedido"],
            "adicionar_item_ao_carrinho": [r'^\d+$'],  # N√∫meros isolados
            "show_more_products": ["mais", "continuar", "pr√≥ximos"],
            "lidar_conversa": ["oi", "ol√°", "bom dia", "boa tarde", "obrigado"]
        }
        
        patterns = high_confidence_patterns.get(tool_name, [])
        for pattern in patterns:
            if re.search(pattern, user_lower):
                return 0.9
        
        # Verifica se h√° inconsist√™ncias lingu√≠sticas
        if len(user_message.strip()) < 2:
            return 0.4  # Mensagens muito curtas
        
        if len(user_message.strip()) > 200:
            return 0.6  # Mensagens muito longas podem ser confusas
        
        return 0.75  # Confian√ßa m√©dia
    
    def _get_historical_success_rate(self, tool_name: str) -> float:
        """Retorna taxa hist√≥rica de sucesso da ferramenta."""
        return self._historical_success.get(tool_name, 0.7)
    
    def update_historical_success(self, tool_name: str, success: bool):
        """Atualiza taxa hist√≥rica de sucesso baseada em feedback."""
        if tool_name not in self._historical_success:
            self._historical_success[tool_name] = 0.7
        
        # Atualiza√ß√£o incremental com peso menor para mudan√ßas graduais
        current_rate = self._historical_success[tool_name]
        adjustment = 0.02 if success else -0.02
        new_rate = max(0.1, min(0.98, current_rate + adjustment))
        
        self._historical_success[tool_name] = new_rate
        logger.debug(f"[CONFIDENCE] Taxa de sucesso atualizada para {tool_name}: {new_rate:.3f}")


class SmartParameterValidator:
    """
    Sistema de Valida√ß√£o Proativa de Par√¢metros com Corre√ß√£o Autom√°tica.
    
    Valida e enriquece par√¢metros ANTES da execu√ß√£o para prevenir erros e 
    melhorar a qualidade das a√ß√µes executadas pela IA.
    """
    
    def __init__(self):
        # Esquemas de valida√ß√£o por ferramenta
        self._validation_schemas = {
            "busca_inteligente_com_promocoes": {
                "required": ["termo_busca"],
                "optional": {},
                "validations": {
                    "termo_busca": {"type": str, "min_length": 1, "max_length": 200}
                }
            },
            "obter_produtos_mais_vendidos_por_nome": {
                "required": ["nome_produto"],
                "optional": {},
                "validations": {
                    "nome_produto": {"type": str, "min_length": 1, "max_length": 100}
                }
            },
            "atualizacao_inteligente_carrinho": {
                "required": ["acao"],
                "optional": ["nome_produto", "quantidade"],
                "validations": {
                    "acao": {"type": str, "allowed": ["add", "remove", "set"]},
                    "quantidade": {"type": int, "min": 1, "max": 10000},
                    "nome_produto": {"type": str, "min_length": 1, "max_length": 100}
                }
            },
            "adicionar_item_ao_carrinho": {
                "required": ["indice"],
                "optional": ["quantidade"],
                "validations": {
                    "indice": {"type": int, "min": 1, "max": 50},
                    "quantidade": {"type": int, "min": 1, "max": 10000}
                }
            },
            "visualizar_carrinho": {
                "required": [],
                "optional": {},
                "validations": {}
            },
            "limpar_carrinho": {
                "required": [],
                "optional": {},
                "validations": {}
            },
            "show_more_products": {
                "required": [],
                "optional": {},
                "validations": {}
            },
            "finalizar_pedido": {
                "required": [],
                "optional": ["cnpj", "force_finalizar_pedido"],
                "validations": {
                    "cnpj": {"type": str, "pattern": r"^\d{14}$"},
                    "force_finalizar_pedido": {"type": bool}
                }
            },
            "lidar_conversa": {
                "required": ["response_text"],
                "optional": {},
                "validations": {
                    "response_text": {"type": str, "min_length": 1, "max_length": 1000}
                }
            }
        }
        
        # Contadores para m√©tricas
        self._validation_stats = {
            "validations_performed": 0,
            "corrections_made": 0,
            "errors_prevented": 0,
            "parameter_enrichments": 0
        }
    
    def pre_validate_intent(self, intent_data: Dict, user_message: str, context: str = "") -> Dict:
        """
        Valida e enriquece par√¢metros ANTES da execu√ß√£o.
        
        Args:
            intent_data: Dados da inten√ß√£o detectada
            user_message: Mensagem original do usu√°rio
            context: Contexto da conversa
            
        Returns:
            Dict: Intent com par√¢metros validados e corrigidos
        """
        self._validation_stats["validations_performed"] += 1
        
        tool_name = intent_data.get("nome_ferramenta", "")
        parametros = intent_data.get("parametros", {}).copy()
        
        logger.debug(f"[VALIDATOR] Validando {tool_name} com par√¢metros: {parametros}")
        
        # 1. Valida√ß√£o de Schema
        validation_result = self._validate_schema(tool_name, parametros)
        if not validation_result["valid"]:
            parametros = self._correct_parameters(tool_name, parametros, validation_result["errors"])
            self._validation_stats["corrections_made"] += 1
        
        # 2. Valida√ß√£o Contextual
        contextual_corrections = self._validate_contextual_consistency(
            tool_name, parametros, context
        )
        if contextual_corrections:
            parametros.update(contextual_corrections)
            self._validation_stats["corrections_made"] += 1
        
        # 3. Enriquecimento de Par√¢metros
        enrichments = self._enrich_parameters(tool_name, parametros, user_message, context)
        if enrichments:
            parametros.update(enrichments)
            self._validation_stats["parameter_enrichments"] += 1
        
        # 4. Valida√ß√£o Final
        final_validation = self._final_validation_check(tool_name, parametros)
        if not final_validation["valid"]:
            # Se ainda h√° problemas cr√≠ticos, marca para fallback
            intent_data["validation_status"] = "failed"
            intent_data["validation_errors"] = final_validation["errors"]
            self._validation_stats["errors_prevented"] += 1
        else:
            intent_data["validation_status"] = "passed"
        
        # Atualiza par√¢metros validados
        intent_data["parametros"] = parametros
        
        logger.debug(f"[VALIDATOR] Resultado: {tool_name} - status: {intent_data.get('validation_status')} - par√¢metros: {parametros}")
        
        return intent_data
    
    def _validate_schema(self, tool_name: str, parametros: Dict) -> Dict:
        """Valida par√¢metros contra schema da ferramenta."""
        schema = self._validation_schemas.get(tool_name, {})
        errors = []
        
        # Verifica par√¢metros obrigat√≥rios
        required = schema.get("required", [])
        for param in required:
            if param not in parametros or parametros[param] is None or parametros[param] == "":
                errors.append(f"Par√¢metro obrigat√≥rio '{param}' faltando")
        
        # Valida tipos e restri√ß√µes
        validations = schema.get("validations", {})
        for param, rules in validations.items():
            if param in parametros:
                value = parametros[param]
                
                # Valida√ß√£o de tipo
                expected_type = rules.get("type")
                if expected_type and not isinstance(value, expected_type):
                    errors.append(f"Par√¢metro '{param}' deve ser {expected_type.__name__}")
                
                # Valida√ß√µes espec√≠ficas
                if expected_type == str:
                    if "min_length" in rules and len(str(value)) < rules["min_length"]:
                        errors.append(f"Par√¢metro '{param}' muito curto")
                    if "max_length" in rules and len(str(value)) > rules["max_length"]:
                        errors.append(f"Par√¢metro '{param}' muito longo")
                    if "pattern" in rules:
                        import re
                        if not re.match(rules["pattern"], str(value)):
                            errors.append(f"Par√¢metro '{param}' formato inv√°lido")
                    if "allowed" in rules and value not in rules["allowed"]:
                        errors.append(f"Par√¢metro '{param}' valor n√£o permitido")
                
                elif expected_type in [int, float]:
                    if "min" in rules and value < rules["min"]:
                        errors.append(f"Par√¢metro '{param}' menor que m√≠nimo")
                    if "max" in rules and value > rules["max"]:
                        errors.append(f"Par√¢metro '{param}' maior que m√°ximo")
        
        return {"valid": len(errors) == 0, "errors": errors}
    
    def _correct_parameters(self, tool_name: str, parametros: Dict, errors: List[str]) -> Dict:
        """Corrige automaticamente par√¢metros com problemas."""
        corrected = parametros.copy()
        
        for error in errors:
            if "faltando" in error:
                # Adiciona par√¢metros obrigat√≥rios faltando
                if "termo_busca" in error:
                    corrected["termo_busca"] = "produtos"
                elif "nome_produto" in error:
                    corrected["nome_produto"] = "produto"
                elif "acao" in error:
                    corrected["acao"] = "add"
                elif "response_text" in error:
                    corrected["response_text"] = "Como posso ajudar?"
                elif "indice" in error:
                    corrected["indice"] = 1
            
            elif "deve ser int" in error:
                # Converte strings para inteiros
                for param in corrected:
                    if isinstance(corrected[param], str) and corrected[param].isdigit():
                        corrected[param] = int(corrected[param])
            
            elif "deve ser str" in error:
                # Converte valores para string
                for param in corrected:
                    if not isinstance(corrected[param], str):
                        corrected[param] = str(corrected[param])
            
            elif "muito longo" in error:
                # Trunca strings longas
                for param in corrected:
                    if isinstance(corrected[param], str) and len(corrected[param]) > 200:
                        corrected[param] = corrected[param][:200]
            
            elif "menor que m√≠nimo" in error:
                # Ajusta valores m√≠nimos
                if "quantidade" in corrected and corrected["quantidade"] < 1:
                    corrected["quantidade"] = 1
                if "indice" in corrected and corrected["indice"] < 1:
                    corrected["indice"] = 1
            
            elif "maior que m√°ximo" in error:
                # Ajusta valores m√°ximos
                if "quantidade" in corrected and corrected["quantidade"] > 10000:
                    corrected["quantidade"] = 10000
                if "indice" in corrected and corrected["indice"] > 50:
                    corrected["indice"] = 50
        
        return corrected
    
    def _validate_contextual_consistency(self, tool_name: str, parametros: Dict, context: str) -> Dict:
        """Valida consist√™ncia com contexto da conversa."""
        corrections = {}
        
        if not context:
            return corrections
        
        context_lower = context.lower()
        
        # Valida√ß√µes contextuais espec√≠ficas
        if tool_name == "adicionar_item_ao_carrinho":
            # Se contexto menciona lista mas √≠ndice parece inv√°lido
            if "lista" in context_lower or "produtos" in context_lower:
                indice = parametros.get("indice", 1)
                if indice > 20:  # Listas raramente t√™m mais de 20 itens
                    corrections["indice"] = min(indice, 10)
        
        elif tool_name == "atualizacao_inteligente_carrinho":
            # Se contexto sugere carrinho vazio mas est√° tentando remover
            if "carrinho vazio" in context_lower and parametros.get("acao") == "remove":
                corrections["acao"] = "add"
        
        elif tool_name == "busca_inteligente_com_promocoes":
            # Se busca muito gen√©rica e contexto sugere categoria espec√≠fica
            termo = parametros.get("termo_busca", "")
            if len(termo) < 3:
                if "cerveja" in context_lower:
                    corrections["termo_busca"] = "cerveja"
                elif "limpeza" in context_lower:
                    corrections["termo_busca"] = "limpeza"
                elif "bebida" in context_lower:
                    corrections["termo_busca"] = "bebidas"
        
        return corrections
    
    def _enrich_parameters(self, tool_name: str, parametros: Dict, user_message: str, context: str) -> Dict:
        """Enriquece par√¢metros com informa√ß√µes impl√≠citas."""
        enrichments = {}
        
        # Enriquecimento baseado na mensagem do usu√°rio
        user_lower = user_message.lower()
        
        if tool_name == "atualizacao_inteligente_carrinho":
            # Detecta quantidade impl√≠cita na mensagem
            if "quantidade" not in parametros:
                import re
                nums = re.findall(r'\b(\d+)\b', user_message)
                if nums:
                    try:
                        qty = int(nums[0])
                        if 1 <= qty <= 10000:
                            enrichments["quantidade"] = qty
                    except ValueError:
                        pass
                
                if "quantidade" not in enrichments:
                    enrichments["quantidade"] = 1
        
        elif tool_name == "adicionar_item_ao_carrinho":
            # Adiciona quantidade padr√£o se n√£o especificada
            if "quantidade" not in parametros:
                enrichments["quantidade"] = 1
        
        elif tool_name == "lidar_conversa":
            # Enriquece resposta baseada no tipo de sauda√ß√£o
            if "response_text" in parametros and parametros["response_text"] == "GENERATE_GREETING":
                if "bom dia" in user_lower:
                    enrichments["response_text"] = "Bom dia! Como posso ajudar voc√™ hoje?"
                elif "boa tarde" in user_lower:
                    enrichments["response_text"] = "Boa tarde! O que voc√™ precisa?"
                elif "boa noite" in user_lower:
                    enrichments["response_text"] = "Boa noite! Em que posso ajudar?"
                else:
                    enrichments["response_text"] = "Ol√°! Sou o G.A.V., como posso ajudar?"
        
        return enrichments
    
    def _final_validation_check(self, tool_name: str, parametros: Dict) -> Dict:
        """Valida√ß√£o final para garantir que par√¢metros est√£o corretos."""
        critical_errors = []
        
        # Verifica√ß√µes cr√≠ticas que n√£o podem ser corrigidas automaticamente
        if tool_name == "adicionar_item_ao_carrinho":
            indice = parametros.get("indice")
            if not isinstance(indice, int) or indice < 1:
                critical_errors.append("√çndice inv√°lido para sele√ß√£o")
        
        elif tool_name == "finalizar_pedido":
            cnpj = parametros.get("cnpj")
            if cnpj and len(str(cnpj).replace("-", "").replace(".", "").replace("/", "")) != 14:
                critical_errors.append("CNPJ inv√°lido")
        
        return {"valid": len(critical_errors) == 0, "errors": critical_errors}
    
    def get_validation_statistics(self) -> Dict:
        """Retorna estat√≠sticas de valida√ß√£o."""
        return self._validation_stats.copy()
    
    def reset_statistics(self):
        """Reseta estat√≠sticas de valida√ß√£o."""
        for key in self._validation_stats:
            self._validation_stats[key] = 0


# Inst√¢ncia global do sistema de valida√ß√£o
_parameter_validator = SmartParameterValidator()

# Inst√¢ncia global do sistema de confian√ßa
_confidence_system = IntentConfidenceSystem()

def get_confidence_system() -> IntentConfidenceSystem:
    """
    Retorna a inst√¢ncia global do sistema de confian√ßa.
    
    Returns:
        IntentConfidenceSystem: Sistema de confian√ßa configurado
    """
    return _confidence_system

def update_intent_success(tool_name: str, success: bool):
    """
    Atualiza o hist√≥rico de sucesso de uma ferramenta.
    
    Args:
        tool_name: Nome da ferramenta que foi executada
        success: Se a execu√ß√£o foi bem-sucedida
    """
    _confidence_system.update_historical_success(tool_name, success)
    logger.info(f"[CONFIDENCE] Feedback registrado para {tool_name}: {'sucesso' if success else 'falha'}")

def get_confidence_statistics() -> Dict:
    """
    Retorna estat√≠sticas do sistema de confian√ßa.
    
    Returns:
        Dict: Estat√≠sticas incluindo taxas de sucesso por ferramenta
    """
    return {
        "historical_success_rates": _confidence_system._historical_success.copy(),
        "cache_stats": obter_estatisticas_intencao()
    }

def get_parameter_validator() -> SmartParameterValidator:
    """
    Retorna a inst√¢ncia global do sistema de valida√ß√£o.
    
    Returns:
        SmartParameterValidator: Sistema de valida√ß√£o configurado
    """
    return _parameter_validator

def get_validation_statistics() -> Dict:
    """
    Retorna estat√≠sticas do sistema de valida√ß√£o.
    
    Returns:
        Dict: Estat√≠sticas de valida√ß√£o e corre√ß√£o de par√¢metros
    """
    return _parameter_validator.get_validation_statistics()

def validate_intent_manually(intent_data: Dict, user_message: str, context: str = "") -> Dict:
    """
    Valida manualmente uma inten√ß√£o (√∫til para testes).
    
    Args:
        intent_data: Dados da inten√ß√£o para validar
        user_message: Mensagem original do usu√°rio
        context: Contexto da conversa
        
    Returns:
        Dict: Intent validado e enriquecido
    """
    return _parameter_validator.pre_validate_intent(intent_data, user_message, context)

def get_combined_statistics() -> Dict:
    """
    Retorna estat√≠sticas combinadas de todos os sistemas.
    
    Returns:
        Dict: Estat√≠sticas completas do classificador
    """
    return {
        "confidence_system": get_confidence_statistics(),
        "validation_system": get_validation_statistics(),
        "cache_system": obter_estatisticas_intencao()
    }

def detectar_intencao_com_sistemas_criticos(entrada_usuario: str, contexto_conversa: str = "", 
                                          historico_conversa: List[Dict] = None,
                                          dados_disponiveis: Dict = None,
                                          dados_sessao: Dict = None) -> Dict:
    """
    Fun√ß√£o principal integrada com todos os sistemas cr√≠ticos implementados.
    
    Integra:
    1. Sistema de Controle de Fluxo Conversacional
    2. Sistema de Preven√ß√£o de Inven√ß√£o de Dados  
    3. Sistema de Redirecionamento Inteligente
    4. Sistema de Confian√ßa e Valida√ß√£o (j√° existentes)
    5. üöÄ NOVO: Sistema de Gest√£o Inteligente de Contexto IA-FIRST
    
    Args:
        entrada_usuario: Mensagem do usu√°rio
        contexto_conversa: Contexto atual da conversa
        historico_conversa: Hist√≥rico completo da conversa
        dados_disponiveis: Dados dispon√≠veis no sistema para valida√ß√£o factual
        dados_sessao: Dados da sess√£o para otimiza√ß√£o de contexto
        
    Returns:
        Dict: Resultado completo com inten√ß√£o, valida√ß√µes e orienta√ß√µes
    """
    logger.info(f"[SISTEMAS_CRITICOS] Processando entrada: '{entrada_usuario}' com contexto: '{contexto_conversa[:50]}...'")
    
    # Inicializa dados se n√£o fornecidos
    if dados_disponiveis is None:
        dados_disponiveis = {}
    if historico_conversa is None:
        historico_conversa = []
    if dados_sessao is None:
        dados_sessao = {"messages": []}  # Estrutura b√°sica para otimiza√ß√£o de contexto

    # üÜï Verifica se estamos aguardando sele√ß√£o e usu√°rio enviou entrada vazia ou '?'
    last_bot_action = dados_sessao.get("last_bot_action")
    mensagem_ajuda = verificar_entrada_vazia_selecao(entrada_usuario, last_bot_action)
    if mensagem_ajuda:
        return {
            "nome_ferramenta": "lidar_conversa",
            "parametros": {"response_text": mensagem_ajuda},
            "tipo_resposta": "redirecionamento_guidance",
            "sistemas_criticos_ativo": True,
            "necessita_redirecionamento": True,
            "validacao_fluxo": {
                "eh_coerente": False,
                "acao": "esclarecer_entrada",
                "mensagem_orientacao": mensagem_ajuda,
            },
            "analise_confusao": {
                "esta_confuso": True,
                "motivo": "entrada_vazia_selecao",
            },
        }
    
    # üöÄ FASE 0: Otimiza√ß√£o Inteligente de Contexto IA-FIRST
    logger.debug("[FASE 0] Otimizando contexto inteligentemente...")
    contexto_otimizado = _context_manager.optimize_context_window(dados_sessao, entrada_usuario)
    memoria_trabalho = _context_manager.maintain_working_memory(dados_sessao, entrada_usuario)
    
    # Usa contexto otimizado se dispon√≠vel, sen√£o usa contexto original
    contexto_para_analise = contexto_otimizado.get("optimized_text", contexto_conversa) or contexto_conversa
    
    logger.info(f"[SISTEMAS_CRITICOS] Contexto otimizado: {len(contexto_conversa)} ‚Üí {len(contexto_para_analise)} chars, "
                f"qualidade: {contexto_otimizado.get('context_quality_score', 0):.2f}, "
                f"estado_conversa: {memoria_trabalho.get('conversation_state', 'unknown')}")
    
    # FASE 1: Valida√ß√£o de Fluxo Conversacional
    logger.debug("[FASE 1] Validando fluxo conversacional...")
    validacao_fluxo = validar_fluxo_conversa(entrada_usuario, contexto_para_analise, historico_conversa)
    
    # FASE 2: Detec√ß√£o de Confus√£o do Usu√°rio
    logger.debug("[FASE 2] Detectando confus√£o do usu√°rio...")
    analise_confusao = detectar_usuario_confuso(entrada_usuario, contexto_para_analise, historico_conversa)

    # üîç An√°lise adicional de confus√£o baseada no hist√≥rico da conversa
    analise_fluxo_conversa = detectar_confusao_conversa(historico_conversa, entrada_usuario)
    if analise_fluxo_conversa.get("esta_confuso"):
        analise_confusao["esta_confuso"] = True
        if not analise_confusao.get("estrategia_redirecionamento") and \
                analise_fluxo_conversa.get("estrategia_redirecionamento"):
            analise_confusao["estrategia_redirecionamento"] = analise_fluxo_conversa["estrategia_redirecionamento"]
    analise_confusao["analise_fluxo_conversa"] = analise_fluxo_conversa
    
    # üöÄ ENRIQUECIMENTO: Usa informa√ß√µes da mem√≥ria de trabalho para melhorar an√°lise
    produtos_ativos = memoria_trabalho.get("active_products", [])
    acoes_pendentes = memoria_trabalho.get("pending_actions", [])
    estado_conversa = memoria_trabalho.get("conversation_state", "unknown")
    
    # Ajusta detec√ß√£o de confus√£o baseado no estado da conversa
    if estado_conversa == "selecting_products" and not entrada_usuario.strip().isdigit():
        analise_confusao["esta_confuso"] = True
        analise_confusao["motivo_confusao"] = "Expected product selection but got text"
    
    if estado_conversa == "finalizing_purchase" and "carrinho" not in entrada_usuario.lower():
        # Se est√° finalizando mas pergunta sobre carrinho, n√£o √© confus√£o
        analise_confusao["esta_confuso"] = False
    
    # FASE 3: Decis√£o sobre como proceder
    deve_redirecionar = (not validacao_fluxo["eh_coerente"] and 
                        validacao_fluxo["acao"] in ["redirecionar", "esclarecer_entrada"]) or \
                       analise_confusao["esta_confuso"]
    
    if deve_redirecionar:
        logger.info("[SISTEMAS_CRITICOS] Usu√°rio necessita redirecionamento - aplicando guidance")
        
        # üöÄ NOVO: Usa mem√≥ria de trabalho para contextualizar redirecionamento
        if acoes_pendentes:
            acao_pendente = acoes_pendentes[0]
            if acao_pendente["task_type"] == "produto_sem_adicao":
                mensagem_guidance = "Vejo que voc√™ estava vendo produtos. Digite o n√∫mero do produto que deseja adicionar ao carrinho! üõí"
            elif acao_pendente["task_type"] == "carrinho_sem_finalizacao":
                mensagem_guidance = "Voc√™ tem itens no carrinho. Digite 'finalizar' para concluir seu pedido ou 'carrinho' para revisar! üìã"
            else:
                mensagem_guidance = validacao_fluxo.get("mensagem_orientacao", "Como posso ajudar voc√™ melhor? ü§ù")
        elif validacao_fluxo["mensagem_orientacao"]:
            mensagem_guidance = validacao_fluxo["mensagem_orientacao"]
        elif analise_confusao["estrategia_redirecionamento"]:
            mensagem_guidance = analise_confusao["estrategia_redirecionamento"]["mensagem"]
        else:
            mensagem_guidance = "Como posso ajudar voc√™ melhor? ü§ù"

        # ‚úÖ Valida√ß√£o final da mensagem de orienta√ß√£o
        validacao_final = aplicar_sistemas_criticos_pos_resposta(mensagem_guidance, dados_disponiveis)
        if validacao_final.get("foi_corrigida"):
            mensagem_guidance = validacao_final["resposta_validada"]

        resultado_redirecionamento = {
            "nome_ferramenta": "lidar_conversa",
            "parametros": {
                "response_text": mensagem_guidance
            },
            "tipo_resposta": "redirecionamento_guidance",
            "validacao_fluxo": validacao_fluxo,
            "analise_confusao": analise_confusao,
            "gestao_contexto": contexto_otimizado,
            "memoria_trabalho": memoria_trabalho,
            "sistemas_criticos_ativo": True,
            "necessita_redirecionamento": True,
            "confidence_score": 0.95,  # Alta confian√ßa no redirecionamento
            "confidence_below_threshold": False,
            "decision_strategy": "execute_immediately",
            "validacao_pos_resposta": validacao_final
        }

        log_decisao_ia(
            resultado_redirecionamento["nome_ferramenta"],
            resultado_redirecionamento["confidence_score"],
            resultado_redirecionamento["decision_strategy"],
        )

        return resultado_redirecionamento
    
    # FASE 4: Detec√ß√£o Normal de Inten√ß√£o (se n√£o precisa redirecionamento)
    logger.debug("[FASE 4] Detectando inten√ß√£o com contexto otimizado...")
    intencao_detectada = detectar_intencao_usuario_com_ia(entrada_usuario, contexto_para_analise)
    
    # üöÄ NOVO: Atualiza mem√≥ria de trabalho com a inten√ß√£o detectada
    memoria_trabalho_atualizada = _context_manager.maintain_working_memory(
        dados_sessao, entrada_usuario, intencao_detectada
    )
    
    # FASE 5: Valida√ß√£o Anti-Inven√ß√£o de Dados e Seguran√ßa
    logger.debug("[FASE 5] Validando resposta final...")

    ferramentas_com_resposta_textual = ["lidar_conversa"]
    if intencao_detectada.get("nome_ferramenta") in ferramentas_com_resposta_textual:
        resposta_texto = intencao_detectada.get("parametros", {}).get("response_text", "")
        if resposta_texto and resposta_texto != "GENERATE_GREETING":
            validacao_final = aplicar_sistemas_criticos_pos_resposta(resposta_texto, dados_disponiveis)
            if validacao_final.get("foi_corrigida"):
                logger.warning("[SISTEMAS_CRITICOS] Resposta corrigida para seguran√ßa/inven√ß√£o")
                intencao_detectada["parametros"]["response_text"] = validacao_final["resposta_validada"]
            intencao_detectada["validacao_pos_resposta"] = validacao_final
    
    # FASE 6: Enriquecimento com dados dos sistemas cr√≠ticos
    intencao_detectada.update({
        "validacao_fluxo": validacao_fluxo,
        "analise_confusao": analise_confusao,
        "gestao_contexto": contexto_otimizado,
        "memoria_trabalho": memoria_trabalho_atualizada,
        "sistemas_criticos_ativo": True,
        "necessita_redirecionamento": deve_redirecionar,
        "recomendacoes_contextuais": analise_confusao.get("recomendacoes", []),
        "contexto_otimizado_usado": True,
        "qualidade_contexto": contexto_otimizado.get("context_quality_score", 0)
    })
    
    logger.info(f"[SISTEMAS_CRITICOS] Inten√ß√£o final: {intencao_detectada['nome_ferramenta']}, "
                f"confian√ßa: {intencao_detectada.get('confidence_score', 0):.2f}, "
                f"fluxo_coerente: {validacao_fluxo['eh_coerente']}, "
                f"contexto_qualidade: {contexto_otimizado.get('context_quality_score', 0):.2f}, "
                f"estado: {memoria_trabalho_atualizada.get('conversation_state', 'unknown')}")

    log_decisao_ia(
        intencao_detectada.get("nome_ferramenta", "unknown"),
        intencao_detectada.get("confidence_score", 0.0),
        intencao_detectada.get("decision_strategy"),
    )

    return intencao_detectada

def aplicar_sistemas_criticos_pos_resposta(resposta_gerada: str, dados_disponiveis: Dict = None) -> Dict:
    """
    Aplica sistemas cr√≠ticos AP√ìS a gera√ß√£o de resposta (para valida√ß√£o final).
    
    Args:
        resposta_gerada: Resposta gerada pelo sistema
        dados_disponiveis: Dados dispon√≠veis para valida√ß√£o factual
        
    Returns:
        Dict: Resultado da valida√ß√£o com resposta corrigida se necess√°rio
    """
    logger.debug("[POS_RESPOSTA] Aplicando valida√ß√£o final...")
    
    if dados_disponiveis is None:
        dados_disponiveis = {}
    
    # Valida√ß√£o anti-inven√ß√£o de dados
    validacao_final = validar_resposta_ia(resposta_gerada, dados_disponiveis)
    resposta_validada = validacao_final["resposta_corrigida"]

    # Verifica√ß√£o de seguran√ßa da resposta
    resposta_segura = verificar_seguranca_resposta(resposta_validada)

    return {
        "resposta_original": resposta_gerada,
        "resposta_validada": resposta_validada,
        "foi_corrigida": validacao_final["foi_corrigida"],
        "confiabilidade": validacao_final["confiabilidade"],
        "resposta_segura": resposta_segura,
        "alertas": validacao_final.get("alertas", []),
        "validacao_detalhes": validacao_final
    }

class IntelligentContextManager:
    """
    Sistema de Gest√£o Inteligente de Contexto e Mem√≥ria IA-FIRST.
    
    Otimiza janela de contexto para m√°xima relev√¢ncia, mant√©m mem√≥ria de trabalho
    focada em informa√ß√µes cr√≠ticas e melhora significativamente a precis√£o contextual.
    """
    
    def __init__(self):
        # Cache de contexto otimizado por sess√£o
        self._context_cache = {}
        
        # Mem√≥ria de trabalho atual
        self._working_memory = {
            "active_products": [],
            "user_preferences": {},
            "pending_actions": [],
            "conversation_state": "initial",
            "discussed_topics": [],
            "current_search_context": None,
            "cart_operations_history": []
        }
        
        # Estat√≠sticas de otimiza√ß√£o
        self._optimization_stats = {
            "contexts_optimized": 0,
            "redundant_info_removed": 0,
            "relevant_history_extracted": 0,
            "working_memory_updates": 0,
            "context_compression_ratio": 0.0
        }
        
        # Palavras-chave por relev√¢ncia contextual
        self._relevance_keywords = {
            "high_priority": ["carrinho", "finalizar", "finalizar pedido", "pedido", "comprar"],
            "medium_priority": ["produto", "buscar", "mostrar", "adicionar", "remover"],
            "low_priority": ["ol√°", "obrigado", "tchau", "como", "vai"]
        }
    
    def optimize_context_window(self, session_data: Dict, current_message: str, 
                               max_context_length: int = 2000) -> Dict:
        """
        Otimiza janela de contexto para m√°xima relev√¢ncia IA-FIRST.
        
        Args:
            session_data: Dados da sess√£o com hist√≥rico completo
            current_message: Mensagem atual do usu√°rio
            max_context_length: Tamanho m√°ximo do contexto otimizado
            
        Returns:
            Dict: Contexto otimizado com informa√ß√µes mais relevantes
        """
        self._optimization_stats["contexts_optimized"] += 1
        logger.debug(f"[CONTEXT_MANAGER] Otimizando contexto para: '{current_message[:50]}...'")
        
        # 1. Extra√ß√£o de hist√≥rico relevante
        relevant_history = self._extract_relevant_history_ia(session_data, current_message)
        
        # 2. Compress√£o de informa√ß√µes redundantes
        compressed_info = self._compress_redundant_information_ia(relevant_history)
        self._optimization_stats["redundant_info_removed"] += len(relevant_history) - len(compressed_info)
        
        # 3. Prioriza√ß√£o de informa√ß√µes cr√≠ticas
        prioritized_context = self._highlight_critical_context_ia(compressed_info, current_message)
        
        # 4. Aplica√ß√£o de peso por rec√™ncia e relev√¢ncia
        weighted_context = self._weight_by_recency_and_relevance_ia(prioritized_context, current_message)
        
        # 5. Constru√ß√£o do contexto otimizado
        optimized_context = self._build_optimized_context_ia(weighted_context, max_context_length)
        
        # 6. Atualiza√ß√£o de cache
        session_id = session_data.get("session_id", "default")
        self._context_cache[session_id] = optimized_context
        
        # C√°lculo da raz√£o de compress√£o
        original_length = sum(len(str(item)) for item in session_data.get("messages", []))
        optimized_length = len(optimized_context.get("optimized_text", ""))
        if original_length > 0:
            self._optimization_stats["context_compression_ratio"] = optimized_length / original_length
        
        logger.info(f"[CONTEXT_MANAGER] Contexto otimizado: {original_length} ‚Üí {optimized_length} chars "
                    f"({self._optimization_stats['context_compression_ratio']:.2%} compress√£o)")
        
        return optimized_context
    
    def maintain_working_memory(self, session_data: Dict, current_message: str, 
                               current_intent: Dict = None) -> Dict:
        """
        Mant√©m mem√≥ria de trabalho focada em informa√ß√µes cr√≠ticas IA-FIRST.
        
        Args:
            session_data: Dados da sess√£o atual
            current_message: Mensagem atual do usu√°rio
            current_intent: Inten√ß√£o detectada (opcional)
            
        Returns:
            Dict: Mem√≥ria de trabalho atualizada
        """
        self._optimization_stats["working_memory_updates"] += 1
        logger.debug(f"[CONTEXT_MANAGER] Atualizando mem√≥ria de trabalho...")
        
        # 1. Rastreamento de produtos discutidos
        active_products = self._track_discussed_products_ia(session_data, current_message)
        self._working_memory["active_products"] = active_products
        
        # 2. Extra√ß√£o de prefer√™ncias declaradas
        user_preferences = self._extract_stated_preferences_ia(session_data, current_message)
        self._working_memory["user_preferences"].update(user_preferences)
        
        # 3. Identifica√ß√£o de a√ß√µes pendentes
        pending_actions = self._identify_incomplete_tasks_ia(session_data, current_intent)
        self._working_memory["pending_actions"] = pending_actions
        
        # 4. Determina√ß√£o do estado da conversa
        conversation_state = self._determine_current_state_ia(session_data, current_message, current_intent)
        self._working_memory["conversation_state"] = conversation_state
        
        # 5. Atualiza√ß√£o de contexto de busca atual
        if current_intent and "busca" in current_intent.get("nome_ferramenta", ""):
            search_term = current_intent.get("parametros", {}).get("termo_busca", current_message)
            self._working_memory["current_search_context"] = {
                "search_term": search_term,
                "timestamp": time.time()
            }
        
        # 6. Registro de opera√ß√µes de carrinho
        if current_intent and "carrinho" in current_intent.get("nome_ferramenta", ""):
            self._working_memory["cart_operations_history"].append({
                "operation": current_intent.get("nome_ferramenta"),
                "message": current_message,
                "timestamp": time.time()
            })
            # Mant√©m apenas √∫ltimas 10 opera√ß√µes
            if len(self._working_memory["cart_operations_history"]) > 10:
                self._working_memory["cart_operations_history"] = \
                    self._working_memory["cart_operations_history"][-10:]
        
        logger.debug(f"[CONTEXT_MANAGER] Mem√≥ria atualizada: estado={conversation_state}, "
                     f"produtos_ativos={len(active_products)}, a√ß√µes_pendentes={len(pending_actions)}")
        
        return self._working_memory.copy()
    
    def _extract_relevant_history_ia(self, session_data: Dict, current_message: str) -> List[Dict]:
        """Extrai hist√≥rico relevante usando IA para an√°lise contextual."""
        messages = session_data.get("messages", [])
        current_lower = current_message.lower()
        relevant_messages = []
        
        # IA identifica mensagens relacionadas por contexto sem√¢ntico
        for msg_data in messages[-20:]:  # Analisa √∫ltimas 20 mensagens
            msg_text = str(msg_data.get("content", "")).lower()
            
            # 1. Relev√¢ncia por palavras-chave contextuais
            relevance_score = 0
            
            # Analisa sobreposi√ß√£o de palavras-chave
            current_words = set(current_lower.split())
            msg_words = set(msg_text.split())
            word_overlap = len(current_words.intersection(msg_words)) / max(len(current_words), 1)
            relevance_score += word_overlap * 0.3
            
            # 2. Relev√¢ncia por t√≥picos relacionados
            if any(keyword in msg_text for keyword in self._relevance_keywords["high_priority"]):
                if any(keyword in current_lower for keyword in self._relevance_keywords["high_priority"]):
                    relevance_score += 0.5
            
            # 3. Relev√¢ncia por sequ√™ncia conversacional
            if "produto" in msg_text and any(word in current_lower for word in ["adicionar", "carrinho", "comprar"]):
                relevance_score += 0.4
            
            if "carrinho" in msg_text and any(word in current_lower for word in ["finalizar", "finalizar pedido", "ver"]):
                relevance_score += 0.4
            
            # 4. Relev√¢ncia por n√∫meros (sele√ß√µes de produtos)
            if any(char.isdigit() for char in current_message) and any(char.isdigit() for char in msg_text):
                relevance_score += 0.2
            
            # Incluir mensagens com relev√¢ncia > 0.3
            if relevance_score > 0.3:
                msg_data["relevance_score"] = relevance_score
                relevant_messages.append(msg_data)
        
        # Ordena por relev√¢ncia
        relevant_messages.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)
        
        self._optimization_stats["relevant_history_extracted"] += len(relevant_messages)
        return relevant_messages[:10]  # Top 10 mais relevantes
    
    def _compress_redundant_information_ia(self, relevant_history: List[Dict]) -> List[Dict]:
        """Comprime informa√ß√µes redundantes usando IA para detectar duplica√ß√µes."""
        if not relevant_history:
            return relevant_history
        
        compressed = []
        seen_patterns = set()
        
        for msg_data in relevant_history:
            msg_text = str(msg_data.get("content", "")).lower()
            
            # IA detecta padr√µes redundantes
            pattern_hash = self._generate_semantic_pattern_hash_ia(msg_text)
            
            if pattern_hash not in seen_patterns:
                compressed.append(msg_data)
                seen_patterns.add(pattern_hash)
            else:
                # Mant√©m apenas se tiver informa√ß√£o adicional significativa
                if len(msg_text) > 50 and "produto" in msg_text:
                    compressed.append(msg_data)
        
        return compressed
    
    def _generate_semantic_pattern_hash_ia(self, text: str) -> str:
        """Gera hash sem√¢ntico para detectar padr√µes similares com IA."""
        # Remove n√∫meros espec√≠ficos e mant√©m padr√£o geral
        import re
        normalized = re.sub(r'\d+', 'N', text)  # Substitui n√∫meros por 'N'
        normalized = re.sub(r'\s+', ' ', normalized.strip())  # Normaliza espa√ßos
        
        # Extrai padr√£o sem√¢ntico principal
        key_patterns = []
        if "carrinho" in normalized: key_patterns.append("cart")
        if "produto" in normalized: key_patterns.append("product")
        if "busca" in normalized: key_patterns.append("search")
        if "finalizar" in normalized: key_patterns.append("finalizar_pedido")
        if "N" in normalized: key_patterns.append("selection")
        
        return "_".join(sorted(key_patterns)) if key_patterns else normalized[:20]
    
    def _highlight_critical_context_ia(self, compressed_info: List[Dict], current_message: str) -> List[Dict]:
        """Destaca informa√ß√µes cr√≠ticas usando IA para prioriza√ß√£o."""
        current_lower = current_message.lower()
        
        for msg_data in compressed_info:
            msg_text = str(msg_data.get("content", "")).lower()
            priority = "normal"
            
            # IA determina prioridade contextual
            if any(keyword in msg_text for keyword in self._relevance_keywords["high_priority"]):
                if any(keyword in current_lower for keyword in self._relevance_keywords["high_priority"]):
                    priority = "critical"
            
            # Prioridade alta para n√∫meros se usu√°rio est√° selecionando
            if current_lower.isdigit() and any(char.isdigit() for char in msg_text):
                priority = "high"
            
            # Prioridade cr√≠tica para √∫ltimas a√ß√µes de carrinho
            if "carrinho" in msg_text and "finalizar" in current_lower:
                priority = "critical"
            
            msg_data["context_priority"] = priority
        
        return compressed_info
    
    def _weight_by_recency_and_relevance_ia(self, prioritized_context: List[Dict], current_message: str) -> List[Dict]:
        """Aplica peso por rec√™ncia e relev√¢ncia usando IA."""
        now = time.time()
        
        for i, msg_data in enumerate(prioritized_context):
            # Peso por rec√™ncia (mensagens mais recentes t√™m peso maior)
            recency_weight = 1.0 - (i * 0.1)  # Decai 10% para cada posi√ß√£o anterior
            
            # Peso por relev√¢ncia
            relevance_weight = msg_data.get("relevance_score", 0.5)
            
            # Peso por prioridade
            priority = msg_data.get("context_priority", "normal")
            priority_weights = {"critical": 1.0, "high": 0.8, "normal": 0.5, "low": 0.3}
            priority_weight = priority_weights.get(priority, 0.5)
            
            # Peso combinado
            combined_weight = (recency_weight * 0.3) + (relevance_weight * 0.4) + (priority_weight * 0.3)
            msg_data["context_weight"] = round(combined_weight, 3)
        
        # Ordena por peso combinado
        prioritized_context.sort(key=lambda x: x.get("context_weight", 0), reverse=True)
        return prioritized_context
    
    def _build_optimized_context_ia(self, weighted_context: List[Dict], max_length: int) -> Dict:
        """Constr√≥i contexto otimizado respeitando limite de tamanho."""
        optimized_parts = []
        current_length = 0
        included_messages = []
        
        for msg_data in weighted_context:
            msg_content = str(msg_data.get("content", ""))
            msg_length = len(msg_content)
            
            if current_length + msg_length <= max_length:
                optimized_parts.append(msg_content)
                current_length += msg_length
                included_messages.append(msg_data)
            else:
                # Se n√£o cabe inteiro, tenta incluir vers√£o resumida
                if msg_data.get("context_priority") == "critical":
                    summary = msg_content[:100] + "..." if len(msg_content) > 100 else msg_content
                    if current_length + len(summary) <= max_length:
                        optimized_parts.append(summary)
                        current_length += len(summary)
                        msg_data["was_summarized"] = True
                        included_messages.append(msg_data)
        
        # Constr√≥i contexto final
        optimized_text = "\n".join(optimized_parts[-10:])  # √öltimas 10 mensagens mais relevantes
        
        return {
            "optimized_text": optimized_text,
            "included_messages": included_messages,
            "total_length": current_length,
            "compression_achieved": True,
            "context_quality_score": sum(msg.get("context_weight", 0) for msg in included_messages) / max(len(included_messages), 1)
        }
    
    def _track_discussed_products_ia(self, session_data: Dict, current_message: str) -> List[Dict]:
        """Rastreia produtos discutidos usando IA para extra√ß√£o sem√¢ntica."""
        products = []
        messages = session_data.get("messages", [])
        current_lower = current_message.lower()
        
        # IA extrai produtos mencionados
        product_keywords = ["cerveja", "skol", "heineken", "brahma", "coca", "produto", "item"]
        
        for msg_data in messages[-10:]:  # √öltimas 10 mensagens
            msg_text = str(msg_data.get("content", "")).lower()
            
            # Detecta men√ß√£o de produtos
            if any(keyword in msg_text for keyword in product_keywords):
                # Extrai contexto do produto
                product_context = {
                    "mentioned_in": msg_text[:100],
                    "relevance_to_current": self._calculate_product_relevance_ia(msg_text, current_lower),
                    "message_timestamp": msg_data.get("timestamp", 0)
                }
                
                if product_context["relevance_to_current"] > 0.3:
                    products.append(product_context)
        
        # Remove duplicados e ordena por relev√¢ncia
        unique_products = []
        seen_contexts = set()
        
        for product in products:
            context_key = product["mentioned_in"][:50]
            if context_key not in seen_contexts:
                unique_products.append(product)
                seen_contexts.add(context_key)
        
        unique_products.sort(key=lambda x: x["relevance_to_current"], reverse=True)
        return unique_products[:5]  # Top 5 mais relevantes
    
    def _calculate_product_relevance_ia(self, product_text: str, current_text: str) -> float:
        """Calcula relev√¢ncia de produto mencionado com mensagem atual usando IA."""
        relevance = 0.0
        
        # Sobreposi√ß√£o de palavras
        product_words = set(product_text.split())
        current_words = set(current_text.split())
        overlap = len(product_words.intersection(current_words))
        relevance += overlap * 0.1
        
        # Contexto de a√ß√µes relacionadas
        action_words = ["adicionar", "carrinho", "comprar", "remover", "finalizar"]
        if any(word in current_text for word in action_words):
            relevance += 0.4
        
        # Contexto num√©rico (sele√ß√µes)
        if any(char.isdigit() for char in current_text):
            relevance += 0.2
        
        return min(relevance, 1.0)
    
    def _extract_stated_preferences_ia(self, session_data: Dict, current_message: str) -> Dict:
        """Extrai prefer√™ncias declaradas pelo usu√°rio usando IA."""
        preferences = {}
        messages = session_data.get("messages", [])
        
        # IA identifica padr√µes de prefer√™ncia
        preference_patterns = {
            "cerveja_preferida": [r"gosto.*cerveja", r"prefiro.*cerveja", r"quero.*cerveja"],
            "categoria_interesse": [r"interesse.*em", r"quero.*categoria", r"busco.*tipo"],
            "quantidade_usual": [r"sempre.*compro", r"geralmente.*levo", r"costumo.*pegar"]
        }
        
        for msg_data in messages:
            msg_text = str(msg_data.get("content", "")).lower()
            
            for pref_type, patterns in preference_patterns.items():
                for pattern in patterns:
                    import re
                    if re.search(pattern, msg_text):
                        preferences[pref_type] = {
                            "stated_in": msg_text[:50],
                            "confidence": 0.8,
                            "timestamp": msg_data.get("timestamp", 0)
                        }
        
        return preferences
    
    def _identify_incomplete_tasks_ia(self, session_data: Dict, current_intent: Dict = None) -> List[Dict]:
        """Identifica tarefas incompletas usando IA para an√°lise de fluxo."""
        pending = []
        messages = session_data.get("messages", [])
        
        # IA detecta fluxos incompletos
        incomplete_patterns = {
            "produto_sem_adicao": {"trigger": "mostrar produtos", "missing": "adicionar carrinho"},
            "carrinho_sem_finalizacao": {"trigger": "visualizar carrinho", "missing": "finalizar pedido"},
            "busca_sem_selecao": {"trigger": "busca produtos", "missing": "selecionar item"}
        }
        
        for msg_data in messages[-5:]:  # √öltimas 5 mensagens
            msg_text = str(msg_data.get("content", "")).lower()
            
            # Verifica padr√µes de tarefas incompletas
            if "produtos encontrados" in msg_text and not any(
                "adicionado" in str(m.get("content", "")).lower() 
                for m in messages[messages.index(msg_data):]
            ):
                pending.append({
                    "task_type": "produto_sem_adicao",
                    "description": "Produtos mostrados mas n√£o adicionados ao carrinho",
                    "priority": "medium",
                    "detected_in": msg_text[:50]
                })
            
            if "carrinho" in msg_text and "finalizar" not in msg_text:
                pending.append({
                    "task_type": "carrinho_sem_finalizacao",
                    "description": "Carrinho visualizado mas pedido n√£o finalizado",
                    "priority": "high",
                    "detected_in": msg_text[:50]
                })
        
        # Remove duplicados
        unique_pending = []
        seen_tasks = set()
        for task in pending:
            task_key = task["task_type"] + task["detected_in"]
            if task_key not in seen_tasks:
                unique_pending.append(task)
                seen_tasks.add(task_key)
        
        return unique_pending
    
    def _determine_current_state_ia(self, session_data: Dict, current_message: str, current_intent: Dict = None) -> str:
        """Determina estado atual da conversa usando IA."""
        current_lower = current_message.lower()
        
        # IA analisa estado baseado em padr√µes conversacionais
        if current_intent:
            tool_name = current_intent.get("nome_ferramenta", "")
            
            state_mapping = {
                "busca_inteligente_com_promocoes": "searching_products",
                "adicionar_item_ao_carrinho": "selecting_products",
                "visualizar_carrinho": "reviewing_cart",
                "atualizacao_inteligente_carrinho": "modifying_cart",
                "finalizar_pedido": "finalizing_purchase",
                "handle_chitchat": "greeting",
                "lidar_conversa": "general_conversation"
            }
            
            detected_state = state_mapping.get(tool_name, "unknown_intent")
        else:
            # Fallback: an√°lise por padr√µes na mensagem
            if any(word in current_lower for word in ["oi", "ol√°", "bom dia"]):
                detected_state = "greeting"
            elif any(word in current_lower for word in ["produto", "busca", "procuro"]):
                detected_state = "searching_products"
            elif current_lower.isdigit():
                detected_state = "selecting_products"
            elif "carrinho" in current_lower:
                detected_state = "reviewing_cart"
            elif "finalizar" in current_lower:
                detected_state = "finalizing_purchase"
            else:
                detected_state = "general_conversation"
        
        return detected_state
    
    def get_optimization_statistics(self) -> Dict:
        """Retorna estat√≠sticas de otimiza√ß√£o do contexto."""
        return {
            "optimization_stats": self._optimization_stats.copy(),
            "working_memory_size": len(str(self._working_memory)),
            "context_cache_size": len(self._context_cache),
            "current_conversation_state": self._working_memory.get("conversation_state", "unknown"),
            "active_products_count": len(self._working_memory.get("active_products", [])),
            "pending_actions_count": len(self._working_memory.get("pending_actions", []))
        }
    
    def reset_working_memory(self):
        """Reseta mem√≥ria de trabalho (√∫til para nova sess√£o)."""
        self._working_memory = {
            "active_products": [],
            "user_preferences": {},
            "pending_actions": [],
            "conversation_state": "initial",
            "discussed_topics": [],
            "current_search_context": None,
            "cart_operations_history": []
        }
        logger.info("[CONTEXT_MANAGER] Mem√≥ria de trabalho resetada")
    
    def get_current_working_memory(self) -> Dict:
        """Retorna c√≥pia atual da mem√≥ria de trabalho."""
        return self._working_memory.copy()


# Inst√¢ncia global do gerenciador de contexto IA-FIRST
_context_manager = IntelligentContextManager()

def get_context_manager() -> IntelligentContextManager:
    """
    Retorna a inst√¢ncia global do gerenciador de contexto.
    
    Returns:
        IntelligentContextManager: Gerenciador de contexto configurado
    """
    return _context_manager

def optimize_context_for_intent(session_data: Dict, current_message: str, 
                               max_context_length: int = 2000) -> Dict:
    """
    Otimiza contexto para detec√ß√£o de inten√ß√£o IA-FIRST.
    
    Args:
        session_data: Dados da sess√£o com hist√≥rico
        current_message: Mensagem atual do usu√°rio
        max_context_length: Tamanho m√°ximo do contexto
        
    Returns:
        Dict: Contexto otimizado para m√°xima relev√¢ncia
    """
    return _context_manager.optimize_context_window(session_data, current_message, max_context_length)

def update_working_memory(session_data: Dict, current_message: str, 
                         current_intent: Dict = None) -> Dict:
    """
    Atualiza mem√≥ria de trabalho com informa√ß√µes da sess√£o atual.
    
    Args:
        session_data: Dados da sess√£o atual
        current_message: Mensagem atual do usu√°rio
        current_intent: Inten√ß√£o detectada (opcional)
        
    Returns:
        Dict: Mem√≥ria de trabalho atualizada
    """
    return _context_manager.maintain_working_memory(session_data, current_message, current_intent)

def get_context_optimization_stats() -> Dict:
    """
    Retorna estat√≠sticas de otimiza√ß√£o de contexto.
    
    Returns:
        Dict: Estat√≠sticas completas do sistema de contexto
    """
    return _context_manager.get_optimization_statistics()

def obter_estatisticas_sistemas_criticos() -> Dict:
    """
    Retorna estat√≠sticas combinadas de todos os sistemas cr√≠ticos.
    
    Returns:
        Dict: Estat√≠sticas completas dos sistemas implementados
    """
    try:
        from .controlador_fluxo_conversa import obter_estatisticas_fluxo
        from .prevencao_invencao_dados import obter_estatisticas_prevencao  
        from .redirecionamento_inteligente import obter_estatisticas_redirecionamento
        
        return {
            "classificador_intencao": get_combined_statistics(),
            "gestao_contexto": get_context_optimization_stats(),
            "fluxo_conversacional": obter_estatisticas_fluxo(),
            "prevencao_invencao": obter_estatisticas_prevencao(),
            "redirecionamento_inteligente": obter_estatisticas_redirecionamento(),
            "sistemas_criticos_ativo": True,
            "versao_sistemas": "1.1.0_21082025"
        }
    except ImportError as e:
        logger.warning(f"[SISTEMAS_CRITICOS] Erro ao importar estat√≠sticas: {e}")
        return {
            "classificador_intencao": get_combined_statistics(),
            "gestao_contexto": get_context_optimization_stats(),
            "sistemas_criticos_ativo": False,
            "erro": str(e)
        }
